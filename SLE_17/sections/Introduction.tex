\section{Introduction}\label{sec:introduction}

The quest for improved modularity, variability and extensibility of
programs has been going on since the early days of Software
Engineering~\cite{McIlroy68}. Modern Programming Languages (PLs) enable a certain
degree of modularity, but they have limitations as illustrated by
well-known problems such as the Expression Problem~\cite{wadler1998expression}. The
Expression Problem refers to the difficulty of writing data
abstractions that can be easily extended with both new operations and
new data variants. Traditionally the kinds of data abstraction found
in functional languages can be extended with new operations, but
adding new data variants is difficult. The traditional object-oriented
approach to data abstraction facilitates adding new data variants
(classes), while adding new operations is more difficult.

To address the modularity limitations of Programming Languages, several
different approaches have been proposed in the past. Existing
approaches can be broadly divided into two categories:
\emph{syntactic} or \emph{semantic} modularization
techniques. Syntactic modularization techniques are quite popular in
practice, due to their simplicity of implementation and use.
Examples include many tools for developing Feature-Oriented Software-Product
Lines (SPLs)~\cite{AK:JOT09,Kastner11road}, some Language Workbenches~\cite{Erdweg201524}, or extensible parser
generators~\cite{antlr1995,Grimm2006,Gouseti2014,Warth2016}.  Most syntactic approaches employ textual
composition techniques such as \emph{superimposition}~\cite{AK:JOT09} to
enable the development modular program features. 
%Such
%composition techniques collect the code for multiple features and
%merge them together when a concrete combination of features is needed
%for a particular program. 
As Kastner et. al~\cite{Kastner11road} note,
a typical drawback of feature-oriented SPL implementations, which
more generally applies to syntactic modularity approaches, is that
such ``\emph{implementation mechanisms lack proper
  interfaces and support neither modular type checking nor separate
  compilation}''.

Syntactic modularization techniques have also been applied to the
problem of \emph{extensible parsing}. Many parser
generators~\cite{antlr1995,Grimm2006,Gouseti2014,Warth2016} support
modular grammars. For instance, \textit{Rats!}~\cite{Grimm2006} has
its own module system for the collection of grammars.  Extensible
compilers like JastAdd~\cite{Ekman2007} and
Polyglot~\cite{Nystrom2003} also support extensible parsing, but this
is mostly done ultimately resorting to standard (non-modular) parser
generators. Various techniques supporting languages that can extend
their own syntax, such as SugarJ~\cite{Erdweg2011}, also offer a form
of extensible parsing. However those syntactic approaches do not
support separate compilation and/or modular type-checking
of parsing code either.

Semantic modularization techniques go one step further in terms of modularity,
and also enable components or features to be modularly type-checked
and separately compiled. Modular type-checking and separate
compilation are desirable properties to have from a software
engineering point-of-view. Modular type-checking can report errors
earlier and in terms of the modular code programmers have written
in the first place. Separate compilation avoids global compilation
steps, which can be very costly. Furthermore semantic modularization
enables the composition of compiled binaries as well as ensuring the
type-safety of the code composed of multiple components. Examples of semantic modularization techniques
include various approaches to \emph{family polymorphism}~\cite{ernst01FP},
\emph{virtual classes}~\cite{Ernst:2006}, as
well as various techniques for solving the Expression
Problem~\cite{torgersen2004expression,odersky2005independently,Oliveira:2012,wang2016expression}.
Semantic modularization techniques are less widely used in practice
than syntactic techniques. This is partly due to the perceived need for more
sophisticated type systems, which are not available in mainstream
languages and may require more knowledge from users. However, recently,
several lightweight modularization techniques have been shown to work
in mainstream programming languages like Java or Scala. Object
Algebras~\cite{Oliveira:2012} are one such technique, which works in
Java-like languages and uses simple generics only.

So far research on semantic modularization techniques has focused on
operations that \emph{traverse} or \emph{process} extensible
data structures, such as ASTs. Indeed many documented applications of
semantic modularization techniques focus on modularizing various
aspects of PL implementations.  However, as far as we know, there is
little work on operations that build/produce ASTs.  In particular the
problem of how to modularize parsing has not been studied in semantic
modularization approaches. At best, techniques such as NOA~\cite{Gouseti2014}
employ a syntactic modularity approach for parsing in combination with
a semantic modularity approach for defining operations
that traverse or process ASTs. This is a shame because parsing is a
fundamental part of PL implementations, and it ought to be made
semantically modular as well, so that the full benefits of semantic
modularity apply.

%\paragraph{Modular and Extensible Parsing}

This paper presents a technique for doing semantically
modular parsing.  That is, our approach not only allows complete
parsers to be built out of modular parsing components, but also enables
those parsing components to be \emph{modularly type-checked} and
\emph{separately compiled}. Developing techniques for modular parsing
is not without challenges. In developing our techniques we encountered
two different classes of challenges: algorithmic challenges; and
typing/reuse challenges.

\paragraph{Algorithmic Challenges} A first challenge was to do with
the parsing algorithms themselves, since they
were usually not designed with extensibility in mind. The most widely used tools for parsing are parser
generators, but they mostly require full information about the grammar to generate parsing
code. Moreover, actions associated with grammar productions are
typically only type-checked after the parser has been
generated. Both problems go against our goals of semantic
modularity.

An alternative to parser generators are \emph{parser
  combinators}~\cite{burge1975,Wadler1985}.  At a first look, parser
combinators seem very suitable for our purpose. Each parser
combinator is represented by a piece of code directly in the
programming language. Thus, in a statically typed programming
language, such code is statically type-checked.  However many
techniques regularly employed by parser combinators cause difficulties in a
modular setting. In particular, many parser combinator approaches
(including Parsec~\cite{Leijen2001}) routinely use \emph{left-recursion
  elimination}, \emph{priority-based matching}, and \emph{avoid
  backtracking} as much as possible. All of these are problematic in
a modular setting as illustrated in Section~\ref{subsec:challenges}.

To address such algorithmic challenges, we propose a methodology
for implementing modular parsers built on top of an
existing Packrat~\cite{Ford2002} parsing library for Scala~\cite{odersky2004overview}. Such a library
directly supports left-recursion, memoization, and a \emph{longest-match
  composition} operator. We will see some examples in Section \ref{subsec:packratparsing}.

\paragraph{Typing and Reusability Challenges} The second class of
challenges was problems related to modularity, reusability and
typing of parsing code. An immediate concern is how to extend a
parser for an existing language or, more generally, how to compose
parsing code for two languages. It turns out that OO mechanisms that
provide some form of multiple inheritance,
such as traits/mixins~\cite{Bracha1990,Scharli2003}, are very handy for this
purpose. Essentially, traits/mixins can act as modules for the parsing code
of different languages. This enables an approach where ASTs can be
modelled using standard OO techniques such as the {\sc Composite}
pattern, while retaining the possibility of adding new language
constructs. Section~\ref{sec:inheritance} gives the details of this approach.

Our ultimate goal is to allow for full extensibility: it should be
possible to modularly add not only new language constructs, but
also new operations. To accomplish this goal one final tweak on our
technique is to employ Object Algebras to allow fully extensible
ASTs. Thus a combination of Packrat parsing, multiple inheritance
and Object Algebras enables a solution for semantically modular
parsing. Section~\ref{sec:algebrasandparsing} gives the details of the complete approach.

To evaluate our approach we conduct a case study based on the ``Types
and Programming Languages'' (TAPL) interpreters. The case study shows
that our approach is effective at reusing parsing code from existing
interpreters, and the total parsing code is 69\% shorter than an
existing code base using non-modular parsing code\footnote{https://github.com/ilya-klyuchnikov/tapl-scala/}.

In summary our contributions are:

\begin{itemize}[leftmargin=*]

\item \textbf{A Technique for Modular Parsing:}
  We present a technique that allows the development of semantically modular parsers.
  The technique relies on the combination of Packrat parsing, multiple inheritance
  and Object Algebras.

\item \textbf{A Parsing Technique for OO ASTs:} A simplified version of
  our technique also enables parsing OO-style ASTs, where new language
  constructs can be easily added.

\item \textbf{A Methodology for Writing Modular Parsers:} We
  identify possible pitfalls using parser combinators. To avoid such
  pitfalls, we propose guidelines for writing parsing code using
  \emph{left-recursion} and \emph{longest-match composition}.

\item \textbf{TAPL case study:} We conduct a case study with 18 interpreters
  from the TAPL book. The case study show the effectiveness of modular
  parsing in terms of reuse. The TAPL case study is available online
  at:
  \url{http://}\footnote{\textbf{Note to Reviewers:} Please find the URL in the
    supplementary material for the submission.}

\end{itemize}

All the code in the paper and the case study is written in Scala, since its concise and elegant
syntax gives better presentation. Clearly
other languages that support some form of multiple inheritance
(including Java 8 with default methods~\cite{Goetz2012}) could in principle be
used.
