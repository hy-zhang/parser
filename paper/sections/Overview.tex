\section{Overview}\label{sec:overview}

\subsection{Choosing the Parsing Technique}\label{subsec:overview-parsing}

%A technique for type-safe modular parsing should the following 3
%features: \emph{modular type-checking}; \emph{separate compilation};
%low performance overhead

Although there are many parsing techniques, not all of them are
suitable for type-safe modular parsing. In particular there are many
techniques which fail to provide modular type-checking and separate
compilation. Moreover, even if modular type-checking and separate
compilation are supported, efficiency is another
concern. A parsing technique should have low overhead when applied
in a modular setting. In the remaider of this section, we eliminate
various techniques that fail to satisfy our requirements, and argue
that that Packrat parsing~\cite{} is a suitable candidate for
type-safe modular parsing.

\paragraph{Parser Generators} The most widely use tools for parsing
are parser generators~\cite{}. Parser generators help users generate parsers automatically or
semi-automatically from a given grammar. There is no restriction on
the algorithm, while most of them adopts table-based LL~\cite{} and LR parsing
algorithms~\cite{}.
Although efficient, the main drawback of parser generators is that they do not support
modular type-checking and separate compilation.

Modular parsing based on parser generators is supported by many libraries []. Users can separate the concrete/abstract syntax and related parsing code into reusable components. Then the corresponding parsers are built by their library utilities. For example, NOA [] uses Java annotation processing to collect grammar information, and then generates ANTLR4 parsers. However, such generation procedure requires a whole compilation after the collection of all grammar pieces. Once the grammar changed, even slightly, grammar information must be re-collected and the parser must be re-generated. Hence those libraries only have syntactic modularity.

Generating parsers often requires full information of grammars, thus semantic modularity is difficult to achieve in this way.

\huang{a paragraph here, refer to related work section, discuss
  previous works of modular parsing using parser generators and its
  drawbacks}\bruno{Please finish this.}\huang{done}

\paragraph{Parser Combinators}
Comparing with the parser generators, a \textit{parser combinator}~\cite{}
takes several parsers and produce a new parser as its output. Parser combinators are
popular in functional programming, where the parsers are represented
by functions and parser combinators are higher-order functions accepts
them.

At a first look, parser combinators are very suitable for our purpose, because of two
reasons. Firstly, they are naturally modular. The manner of using them
is to write small parsers and use combinators to composed them
together. The construction procedure is explicit and fully controlled
by the programmer. Secondly, each parser combinator is represented by
a piece of code, and also are the parsers it takes. Thus in a
statically typed programming language they can be statically
type-checked.

Unfortunately many parser combinators have important limitations for
modular parsing. In particular several parser combinators,
including the famous library Parsec~\cite{} library, require
programmers to manually do \textit{left-recursion elimination}, and
require significant amounts \textit{backtracking}. Both of these are
problematic in a modular setting.

\paragraph{Left-Recursion Elimination} The top-down, recursive descent parsing strategy adopted by those parser combinator libraries cannot support left-recursive grammars directly. The common solution is to rewrite the grammar into an equivalent but not left-recursive one, so called left-recursion elimination.

A left-recursive grammar of adding integers can be rewritten as below. On the right side, we got a new grammar without left-recursion.

\begin{tabular}{m{0.4\linewidth}m{0.4\linewidth}}
\setlength{\grammarindent}{5em}
\begin{grammar}
<expr> ::= <int> \alt <expr> `+' <int>
\end{grammar}
&
\setlength{\grammarindent}{5em}
\begin{grammar}
<expr> ::= <int> <expr'>

<expr'> ::= <empty> \alt `+' <int> <expr'>
\end{grammar}
\end{tabular}

The main problem with left-recursion elimination is that it is a \emph{global} transformation on a grammar. Given that the full grammar is known, then it is possible to remove all left-recursive cases. However, when doing modular parsing, the full grammar is not known!

For the example above, if we extend the original grammar to support subtraction, we must analyse the full grammar again to rewrite it.

\begin{tabular}{m{0.4\linewidth}m{0.4\linewidth}}
\setlength{\grammarindent}{5em}
\begin{grammar}
<expr> ::= <int> \alt <expr> `+' <int> \alt <expr> `-' <int>
\end{grammar}
&
\setlength{\grammarindent}{5em}
\begin{grammar}
<expr> ::= <int> <expr'>

<expr'> ::= <empty> \alt `+' <int> <expr'> \alt `-' <int> <expr'>
\end{grammar}
\end{tabular}

Another issue of left-recursion elimination is that it requires extra bookkeeping work to retain the original semantic. For example, the expression $1+2-3$ is parsed as $(1+2)-3$ in the left-recursive grammar, but after rewrite the result is $1((+2)-3))$. The parse tree must be transformed to recover its structure.

\huang{done, the example may be not very good, but i haven't found a better one}\bruno{Illustrate with a concrete example: show a simple
  left-recursive grammar; then do left-recursion elimination. Then add
a new case into the original left-recursive grammar; and show that
a very different grammar is obtained after left-recursion elimination.}

\paragraph{Backtracking} The need for backtracking is also problematic
in a modular setting. Take Parsec as an example, its choice
combinator only tries the second alternative if the first fails
without any token consumption. If two alternatives have a same
non-empty prefix, an auxiliary function \inlinecode{try} must be added
to backtrack. However, if we want to extend our parsers later, we
should always consider the worst case in which all alternatives share
common prefixes. Then we need to add \inlinecode{try} for all the
branches, which results worst case exponential time complexity.
\huang{done}\bruno{you should again illustrate your point here with an
  example. The example should illustrate that the addition of a new
  case may require introducing backtracking. }

For example, suppose that we only have \inlinecode{import..from} statements before, now we want to extend the grammar to add an \inlinecode{import..as} case. The third line of grammar below is the new case.

\setlength{\grammarindent}{5em}
\begin{grammar}
<stmt> ::= `import' <ident> `from' <ident>
    \alt ...
    \alt `import' <ident> `as' <ident>
\end{grammar}

Because the new case \inlinecode{import..as} shares a prefix with the old case \inlinecode{import..from}, we must backtrack in order to cover all possibilities.

\begin{lstlisting}[language=PlainCode]
oldParser = parseImportFrom <|> ...
newParser = try parseImportFrom <|> ... <|> parseImportAs
\end{lstlisting}

\paragraph{Packrat Parsing}
Fortunately more advanced parsing techniques such as Packrat
parsing~\cite{}, address the limitations of simple parser combinators
such as Parsec. Packrat parsers use
memorization to record the result of applying each parser at each
position of the input, so that repeated computation is eliminated, and
they supports left-recursive grammars directly. All of these properties are very
suitable for modularity, thus we use Packrat parsers as the underlying
parsing technique. In section \ref{sec:packratparsers}, we will give
an overview of the Packrat parsing library implemented in Scala,
which we use.

It is worth mentioning that the choice of parser combinators will not
affect the other parts of our library. One can choose other parser
combinators like Parsec, in cases that the performance and supporting
of left-recursion are not major concerns.

\subsection{The Parsing Expression Problem}
\huang{done, added the attempt/failure/reason of extending conventional parsers}\bruno{You are not motivating the problem! You are going straight to
  the solution without pointing out what the problem is first. What
  you need to do is: First show what happens with conventional
  parsers: at some point, if you add extensions the recursive calls
  will be wrong. Then you show (in the next section) the solution:
 use delegation/open recursion.}

\huang{partly done, only extend a new language construct in the example, how about leaving extension of new operations in the OA subsection?}\bruno{I think we need to set up a challenge here, similar to the challenge of
  the expression problem. The challenge should be like. Build a parser
for a simple expression language, then extend the language with both
a new language construct and a new operation. This section will show
how we can do that using traditional parsers, but without modular
type-safety and separate compilation. The remaining sections will show
that the techniques introduced by us, enable us to solve those two challenges.}

Typical parsers defined parser combinators follow the grammar
structure, and build a corresponding AST. If the grammar is changed to
add a new alternative, the corresponding parser has to be changed as
well. Thus the traditional style of developing parsers is not
extensible, and it is at odds with object-oriented programming ASTs,
which support the easy addition of new alternative classes. We
illustrate this problem with a simple expression language and extension.

Suppose we want to parse a simple language of variables and
applications.

\setlength{\grammarindent}{5em}
\begin{grammar}
<expr> ::= <ident>
    \alt <expr> <expr>
    \alt `(' <expr> `)'
\end{grammar}

It is straightforward to model ASTs by inheritance and write corresponding parsers for each case. \huang{This is the first time to demonstrate code in this paper. Readers may not know what those combinators/types are. Refer to the library docs here? move the 'scala parsing library' section to the beginning as 'background'?}

\lstinputlisting[linerange=8-18]{../Scala/Parser/src/PaperCode/Overview/Overview.scala}% APPLY:linerange=OVERVIEW_SIMPLE_EXPR

As the combination of \inlinecode{pVar} and \inlinecode{pApp}, \inlinecode{pExpr} can parse expressions correctly.

\paragraph{Attempt to Extend the Parser} Now consider we are extending the abstract syntax as well as the parsers. We add lambda abstractions as a new case of expressions. The language then becomes the famous \textit{untyped lambda calculus}.

\setlength{\grammarindent}{5em}
\begin{grammar}
<expr> ::= ...
    \alt `\\' <ident> `.' <expr>
\end{grammar}

The ASTs can be extended trivially as below.

\lstinputlisting[linerange=22-22]{../Scala/Parser/src/PaperCode/Overview/Overview.scala}% APPLY:linerange=OVERVIEW_SIMPLE_LAM

Since we already have the parser for variables and applications, we would like to build the new parser by reusing the old one. So we compose \inlinecode{pLam}, which parses lambda abstractions, with the old parser. \inlinecode{pExtExpr} is the new function to parse expressions.

\lstinputlisting[linerange=26-32]{../Scala/Parser/src/PaperCode/Overview/Overview.scala}% APPLY:linerange=OVERVIEW_SIMPLE_EXT

Unfortunately, this extended parser does not work properly to parse all possible expressions defined by the new grammar. For example, it fails to parse \inlinecode{(\x.x)} \inlinecode{(\y.y)} which is obviously valid.

\paragraph{Problem: Hard-coded Recursive Calls} The critical problem of extending parsers directly is that the recursive calls in old parsers are hard-coded. Specifically, \inlinecode{pApp} makes two recursive calls to parse two consecutive expressions as an application. Before the extension, we implemented it by using \inlinecode{pExpr} for those recursive calls. It worked fine at that time because \inlinecode{pExpr} covers all cases of the old grammar. However, after the extension of lambda abstractions, the proper function for such recursive calls should be \inlinecode{pExtExpr} instead of \inlinecode{pExpr}, because the new function \inlinecode{pExtExpr} covers all of the three cases in the new grammar, including the lambda case.

That is the reason why the extended parser fails to parse some valid expressions such as \inlinecode{(\x.x)} \inlinecode{(\y.y)}. To resolve this issue, we need to let \inlinecode{pApp} be aware of the change of grammar. We have some direct solutions:

\begin{itemize}
    \item Keep the old code, rewrite problematic functions like \inlinecode{pApp}. \\Separate compilation is obtained but code reuse is lost, because every function may contain such recursive calls.
    \item Modify the old code, correct the recursive calls by proper functions. \\We can avoid code duplication thus get code reuse, but separate compilation is lost because of modification on the old code.
    \item ??? \huang{third one? use dynamic languages?}
\end{itemize}

Similar to the trade-off in the Expression Problem, neither of them satisfies us. The challenge of building semantically modular parsers requires fundamental change of the parser structure. We will introduce our solution in the next sections.

\subsection{Delegation-Based Parsing}\label{subsec:overview-firstlook}

Hard-coded recursive calls prevent our parsers from extensibility.
This problem can be solved using delegation, which can be encoded with \textit{open recursion}. The idea is
simple: instead of making direct recursive calls, an additional
argument, that abstracts over the recursive call, is passed to the
parsers. This technique enables the developement of parsers that
support OO-style extensibility of ASTs.

\paragraph{Open Parsing} Consider the expression language of only variables and applications in the previous section. The parser can be rewritten as follows:

\lstinputlisting[linerange=53-63]{../Scala/Parser/src/PaperCode/Overview/Overview.scala}% APPLY:linerange=OVERVIEW_OPEN_BASE

According to the definition of type synonym \inlinecode{Open[T]}, every parse function takes a parser of \inlinecode{Expr} as a parameter, namely \inlinecode{self}. This parameter \inlinecode{self} represents \emph{the parser} of expressions, which is dynamiclly explained by the argument. Using an abstract parameter provides extensibility to parsers, because the recursive calls are not hard-coded here --- they are dynamic and can be changed corresponding to the grammar!

We take \inlinecode{pApp} as an example again. It uses \inlinecode{self} instead of hard-coded \inlinecode{pExpr} for recursive parsing. Depending on the real argument, \inlinecode{self} can be a parser which covers only variables and applications, or a parser which also supports the lambda case.

\paragraph{Client Code} Since the type of parsing functions are changed, we can not apply them directly. The client code below shows how to use the new parser. The \inlinecode{fix} function, which is the the standard \textit{fixpoint combinator}, is used to `close' the open recursion.

\lstinputlisting[linerange=68-75]{../Scala/Parser/src/PaperCode/Overview/Overview.scala}% APPLY:linerange=OVERVIEW_OPEN_USE

\huang{done}\bruno{Please polish up code. You probably want to consistently use
the variable name ``self'' whenever you want to refer to the whole
parser (instead of ``e'' that you use at the moment). Also you should
use ``Open'' (which you currently call ``Fix'') instead of using the
longwinded ``(=> PackratParser[Expr]) => PackratParser[Expr]''}

\huang{done}\bruno{Also, for consistency, why isn't ``pVar'' open? I.e. using a
  self reference as well? I know that it is not recursive, but giving
  it a different treatment makes it more confusing for users.}

\huang{done}\bruno{You should use a more OO approach in the example.
Rather than case classes show an Expr trait with pretty printing.
This will enable you to talk about the extensibility and object
algebras better later on.
}


\paragraph{Extensibility} As same as what we did in previous section, we extend the grammar by adding lambda abstractions as a new case. Similarly, the new parser extends from the old one by adding \inlinecode{pLam} on it. Notice that the old code is not touched, hence separate compilation is obtained.

\lstinputlisting[linerange=80-86]{../Scala/Parser/src/PaperCode/Overview/Overview.scala}% APPLY:linerange=OVERVIEW_OPEN_EXT

All recursive calls of parsing `an expression' are called via the explicit parameter \inlinecode{self}. Once the \inlinecode{fix} function is applied, these calls will be updated appropriately. Parsing functions such as \inlinecode{pApp} do not need to be rewritten. As a consequence, this parser recognizes all valid expressions of the new grammar, including \inlinecode{(\\x.x)} \inlinecode{(\\y.y)} which cannot be parsed in the previous section.

\lstinputlisting[linerange=95-95]{../Scala/Parser/src/PaperCode/Overview/Overview.scala}% APPLY:linerange=OVERVIEW_OPEN_EXT_USE

As we demonstrated, delegation encoded by open recursion is the key technique to obtain semantic modularity. It enables type-safe code reuse and separate compilation in our parsers. We will discuss this topic further in section \ref{sec:openandparsing}.

\subsection{Object Algebras for full Extensibility}\label{subsec:overview-oa}

Although delegation enables OO extensibility, the use of an OO class
hierarchy makes the addition of new operations over the AST
problematic. Object Algebras~\cite{} enable us to solve this problem, and
offer high flexibility in the choice of operations to be performed
over the AST. It also makes parsing with multiple sorts of syntax easier.

\paragraph{Parsing with Object Algebras} Using Object Algebras, the abstract syntax of the language of variables and applications is defined as below.

\lstinputlisting[linerange=8-11]{../Scala/Parser/src/PaperCode/Overview/OA.scala}% APPLY:linerange=OVERVIEW_OA_ALG

Then we are able to define operations over the syntax in an extensible way. Here we write a pretty printing operation for this language.

\lstinputlisting[linerange=15-18]{../Scala/Parser/src/PaperCode/Overview/OA.scala}% APPLY:linerange=OVERVIEW_OA_PRINT

And also parser for it as below. Notice the parsing function \inlinecode{pExpr} takes an argument of type \inlinecode{ExprAlg[E]}, that means it accepts any instance of the algebra interface \inlinecode{ExprAlg}.

\lstinputlisting[linerange=22-28]{../Scala/Parser/src/PaperCode/Overview/OA.scala}% APPLY:linerange=OVERVIEW_OA_PARSER

To use the parser, we must provide an algebra instance as the operation to construct the parsing result. As shown in the code below, we feed the pretty printing operation \inlinecode{ExprPrint} to the generic \inlinecode{parse} function. It will print \inlinecode{(x y)} as the result.

\lstinputlisting[linerange=38-43]{../Scala/Parser/src/PaperCode/Overview/OA.scala}% APPLY:linerange=OVERVIEW_OA_USE

\paragraph{Extensibility of Syntax} Following previous examples, the code below shows how to extend the language to support lambda abstractions.

\lstinputlisting[linerange=48-62]{../Scala/Parser/src/PaperCode/Overview/OA.scala}% APPLY:linerange=OVERVIEW_OA_EXT

For easily combining parsers using Object Algebras as ASTs, we have a special combinator \huang{we need to rename our combinator} defined in our library.

\paragraph{Extensibility of Operations} With Object Algebras, operations over ASTs can also be extended in a modular way. Here is an example of collecting free variables from an expression. We can use this new operation during parsing.

\lstinputlisting[linerange=75-81]{../Scala/Parser/src/PaperCode/Overview/OA.scala}% APPLY:linerange=OVERVIEW_OA_EXT_OP


\paragraph{Multiple Sorts of Syntax} Another advantage of using Object Algebras is that it supports multiple sorts of syntax easily. In several cases, we want to divide the syntactic elements into some groups. For example, the grammar below has two sorts, which are expressions and types.

\begin{tabular}{m{0.4\linewidth}m{0.4\linewidth}}
\setlength{\grammarindent}{5em}
\begin{grammar}
<type> ::= `int' \alt <type> `->' <type>
\end{grammar}
&
\setlength{\grammarindent}{5em}
\begin{grammar}
<expr> ::= <ident> \alt <expr> <expr> \alt `\\' <ident> `.' <expr>
\end{grammar}
\end{tabular}

Using Object Algebras, we can easily distinguish them in an extensible way, just by adding an extra type parameter.

\lstinputlisting[linerange=66-70]{../Scala/Parser/src/PaperCode/Overview/OA.scala}% APPLY:linerange=OVERVIEW_OA_MULTI_SYNTAX

