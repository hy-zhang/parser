\section{Overview}\label{sec:overview}

\subsection{The Choice of Parsing Techniques}\label{subsec:overview-parsing}

Parsing techniques have been heavily studied over the years, especially for context-free grammars and its subsets. However, the choice of parsing techniques is not a minor issue in a modular setting. To achieve type-safe modularity, the parsers must be able to be extended and composed, and different parsing techniques have different suitability for that.

Although every parsing algorithm can be implemented by hand in principle, some of them are not friendly for that. A \textit{parser generator} is a tool to help users generate parsers automatically or semi-automatically from a given grammar. There is no restriction on the algorithm, while most of them adopts table-based LL and LR parsing algorithms.

\huang{a paragraph here, refer to related work section, discuss previous works of modular parsing using parser generators and its drawbacks}

Comparing with the parser generators, a \textit{parser combinator} takes several parsers and produce a new parser as its output. It is popular in functional programming, where the parsers are represented by functions and parser combinators are higher-order functions accepts them.

Parser combinators are very suitable for our purpose, because of two reasons. Firstly, they are naturally modular. The manner of using them is to write small parsers and use combinators to composed them together. The construction procedure is explicit and fully controlled by the programmer. Secondly, each parser combinator is represented by a piece of code, and also are the parsers it takes. Thus in a statically typed programming language they can be type-checked during compile time.

Parser combinators adopt top-down, recursive descent parsing, which uses backtracking to search through the possible branches. However, simple backtracking parser combinators such as the famous library Parsec in Haskell, have some drawbacks. One is that they cannot support left-recursive grammars. The common solution is to rewrite a left-recursive grammar into an equivalent one, so called \textit{left-recursion elimination}. This solution requires information of the whole grammar, so that it cannot be applied in a modular setting. Because the grammar may be extended in the future, essentially we only have parts of the grammar. Another drawback is performance. Take Parsec as an example, its choice combinator only tries the second alternative if the first fails without any token consumption. If two alternatives have a same non-empty prefix, an auxiliary function \lstinline{try} must be added to backtrack. However, if we want to extend our parsers later, we should always consider the worst case in which all alternatives share common prefixes. Then we need to add \lstinline{try} for all the branches, which results worst case exponential time complexity.

Beyond the simple backtracking one, several advanced parser combinators were studied to resolve those issues. One of them is Packrat parsers, which is our choice. The details of Packrat parser are beyond the scope of this paper. In brief, Packrat parsers use memorization to record the result of applying each parser at each position of the input, so that repeated computation is eliminated, and it supports left-recursive grammars. All of these properties are very suitable for modularity, thus we use Packrat parsers as the underlying parsing technique. In section \ref{sec:packratparsers}, we will talk about the Packrat parsing library implemented in Scala, which we use.

It is worth mentioning that the choice of parser combinators will not affect the other parts of our library. One can choose other parser combinators like Parsec, in cases that the performance and supporting of left-recursion are not major concerns.

\subsection{Modular Parsers, the First Look}\label{subsec:overview-firstlook}

With Packrat parser combinators, we obtain the possibility of writing parsers in a modular way. Let's start by looking at how to build a parser for a simple language, which only has variables and applications at the beginning.

\begin{lstlisting}[language=PlainCode]
Expr := Var String | App Expr Expr
\end{lstlisting}

Firstly, we define the abstract syntax by Scala's convenient case classes. Expressions have type \lstinline{Expr}, and each of them is either \lstinline{Var} or \lstinline{App}.

\begin{lstlisting}
abstract class Expr
case class Var(x: String) extends Expr
case class App(e1: Expr, e2: Expr) extends Expr
\end{lstlisting}

And then we write parsing functions for each case.

\begin{lstlisting}
val pVar: PackratParser[Expr] =
  ident ^^ Var

val pApp: (=> PackratParser[Expr]) => PackratParser[Expr] =
  e => e ~ e ^^ { case e1 ~ e2 => App(e1, e2) }
\end{lstlisting}

The \lstinline{PackratParser} type and the combinators are imported from the Scala Packrat parsing library. Some details about these structures will be discussed in later sections, so that readers could only focus on the types of these functions at the first reading.

\lstinline{pVar} is straight forward. It parses a single identifier, and its type \lstinline{PackratParser[Expr]} indicates the result is an \lstinline{Expr}. However the type of \lstinline{pApp} is different. It takes a parser of \lstinline{Expr} as an argument, which represents the parser of the whole expression, namely \lstinline{e} here. And use it to parse two consecutive expressions as an application. In this particular case, the parser of the whole expression is in fact the combination of \lstinline{pVar} and \lstinline{pApp}. We can write equivalent code as below.

\begin{lstlisting}
val pApp2: PackratParser[Expr] = {
  lazy val e = pApp2 | pVar
  e ~ e ^^ { case e1 ~ e2 => App(e1, e2) }
}
\end{lstlisting}

\lstinline{pApp2} works fine, but it does not have the extensibility as \lstinline{pApp} does. Since the parser of the whole expression in \lstinline{pApp2} is hard-coded, it covers and only covers the variable and application cases. If we we extend \lstinline{Expr} later to add a third case lambda abstraction, we have to edit the existing code. The parameterization technique used in \lstinline{pApp} is called \textit{open recursion}, which is discussed in section \ref{sec:openandparsing}.

We can use a trait to glue them together, and define \lstinline{pVarApp} as a combination of the two parsing functions. A type synonym \lstinline{Fix} is used to shorten the types.

\begin{lstlisting}
type Fix[T] = (=>T) => T

trait ExprParser {
  lexical.delimiters += ("(", ")")
  val pVar: PackratParser[Expr] =
    ident ^^ Var
  val pApp: Fix[PackratParser[Expr]] =
    e => e ~ e ^^ { case e1 ~ e2 => App(e1, e2) }
  val pVarApp: Fix[PackratParser[Expr]] =
    e => pApp(e) | pVar | "(" ~> e <~ ")"
}
\end{lstlisting}

Finally, we are able to parse \lstinline{Expr} frome strings as shown in the code below. The \lstinline{fix} function here is just the standard \textit{fixpoint}, it is explained in section \ref{subsec:openrecursion}.

\begin{lstlisting}
def parseAndPrint(p: Fix[PackratParser[Expr]])(inp: String) = {
  val t = phrase(fix(p))(new lexical.Scanner(inp))
  if (t.successful) println(t.get) else scala.sys.error(t.toString)
}

val p = new ExprParser {}.pVarApp
parseAndPrint(p)("x y")
\end{lstlisting}

It will print \lstinline{App(Var(x),Var(y))} as the parsing result of string \lstinline{"x y"}.

\subsection{Extend and Reuse Parsers}\label{subsec:overview-extend}

We have done our modular parser, and it behaves just in a normal way. To demonstrate the advantages of writing modular parsers, we extend the language to add lambda abstractions as a new case of expressions. The language then becomes the famous \textit{untyped lambda calculus}.

\begin{lstlisting}[language=PlainCode]
Expr := Var String | App Expr Expr | Lam String Expr
\end{lstlisting}

With Scala's case classes, extending the abstract syntax \lstinline{Expr} is easy.

\begin{lstlisting}
case class Lam(x: String, e: Expr) extends Expr
\end{lstlisting}

Since we already have the parser for variables and applications, we want to reuse it and build a new parser by extending it. It is just what the code below does. Notice that the old code is not touched, hence separate compilation is obtained.

\begin{lstlisting}
trait LambdaParser extends ExprParser {
  lexical.delimiters += ("\\", ".")
  val pLam: (=> PackratParser[Expr]) => PackratParser[Expr] =
    e => "\\" ~> ident ~ ("." ~> e) ^^ { case x ~ b => Lam(x, b) }
  val pVarAppLam: (=> PackratParser[Expr]) => PackratParser[Expr] =
    e => pLam(e) | pVarApp(e)
}
\end{lstlisting}

In the new parser \lstinline{LambdaParser} extended from the old one, we write a new parsing function \lstinline{pLam} for the new case lambda abstraction. And compose it with \lstinline{pVarApp}, which we already have in the old parser \lstinline{ExprParser}. Open recursion is critical to achieve such type-safe compositions, because wherever we refer to the parser of the whole expression, it is updated to cover all of the three case we have now.

\begin{lstlisting}
val p = new LambdaParser {}.pVarAppLam
parseAndPrint(p)("(\\x.x) y")
\end{lstlisting}

The code above will print result \lstinline{App(Lam(x,Var(x)),Var(y))} from parsing \lstinline{"(\\x.x)} \lstinline{y"}.

\subsection{Object Algebras and More}\label{subsec:overview-oa}

Instead of define the abstract syntax using Scala's case classes, we can use \textit{Object Algebras} for more extensibility. Object Algebras is a technique to solve the \textit{Expression Problem}, providing the possibility of extending both data variants and operations over them. It will be further discussed in section \ref{sec:algebrasandparsing}.

Using Object Algebras, the abstract syntax of the language of variables and applications is defined as below.

\begin{lstlisting}
trait VarApp[E] {
  def Var(x: String): E
  def App(e1: E, e2: E): E
}
\end{lstlisting}

% \begin{itemize}
% \item Choosing the Parsing Technology
%     \begin{itemize}
%     \item Parser Generators : why not?
%         \begin{itemize}
%             \item Not type-safe
%             \item No modular type-checking
%             \item Not modular or no separate compilation (but we need to mention lots of work on extensible parsing here: example Language Workbenches; Rats)
%         \end{itemize}
%     \item Parser Combinators
%         \begin{itemize}
%         \item Backtracking parsers (Parsec)
%             \begin{itemize}
%             \item Need to remove left recursion (Problem: Transformation is not modular; if we do not know the full grammar then cannot be done)
%             \item Need try/backtracking (Problem: Since we do not know the full set of rules in a modular setting, we have to assume worst case scenario and add redundant backtracking. )
%             \item Mention some possible workarounds (there may be some but they still have issues)
%             \end{itemize}
%         \item (Non)-Backtracking/Packrat Parsers (Works well in a modular setting) (find a good name for this type of parsers?)
%         \end{itemize}
%     \end{itemize}
% \item Adapting Parser Combinators for modularity
%     \begin{itemize}
%     \item Using Object Algebras
%     \item Using Open Recursion
%     \item Using new modular parser combinators (Library: new alternative combinator, for example)
%     \end{itemize}
% \item Small example
%     \begin{itemize}
%     \item small example of a modular parser using our technique
%     \item show also the same example without modularity and write a detailed comparison
%     \item Lambda Calculus is a good candidate for the example
%     \item Show a small extension (adding plus and numeric literals)
%     \end{itemize}
% \end{itemize}
