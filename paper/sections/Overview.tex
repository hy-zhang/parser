\section{Overview}\label{sec:overview}

This section gives an overview of our library \name, and the problem that motivates our work. Basically, \name consists of four parts: underlying parsing technique, delegation mechanism encoded by open recursion, Object Algebras, and glue code of new combinators and utility functions. We start from Section \ref{subsec:overview-parsing}, which discusses the choice of parsing technique and how it affects modularity of parsers. Section \ref{subsec:overview-problem} demonstrates the goal of extending parsers together with ASTs in a semantic modular way, with both separate compilation and type-safe code reuse. Then we will see traditional parser combinators fail to achieve it because of hard-coded recursive calls. In Section \ref{subsec:overview-delegation}, we show how delegation can solve this problem and allow us to build extensible parsers. Finally, Section \ref{subsec:overview-oa} gives examples of using Object Algebras for more extensibility, including extension of operations and parsing multiple sorts of syntax.\haoyuan{TODO}

\begin{comment}
\subsection{Choosing the Parsing Technique}\label{subsec:overview-parsing}

%A technique for type-safe modular parsing should the following 3
%features: \emph{modular type-checking}; \emph{separate compilation};
%low performance overhead

In the last section, we have argued that parser combinators are a suitable parsing technique for
our purpose, as they naturally build modular parsers for type-checking.
Unfortunately many parser combinators have important limitations.
In particular several parser combinators,
including the famous Parsec~\cite{Leijen2001} library, require
programmers to manually do \textit{left-recursion elimination} and \textit{longest match composition}, and
require significant amounts of \textit{backtracking}. All of them are
problematic in a modular setting.




\paragraph{Packrat Parsing}
Fortunately some more advanced parsing techniques such as Packrat
parsing~\cite{Ford2002}, address the limitations of simple parser combinators
such as Parsec. Packrat parsers use
memoization to record the result of applying each parser at each
position of the input, so that repeated computation is eliminated.
Moreover, theoretically the algorithm behind Packrat parsers
supports both direct and indirect left-recursion~\cite{warth2008}.
The current version of the library is still
buggy with indirect left-recursion, but we believe that
they will fix it in the future, and direct left-recursion is
already practical to use for a large number of applications. All of these properties are very
suitable for modularity, thus we decided to use Packrat parsers as the underlying
parsing technique in \name.


It is worth mentioning that the choice of parser combinators will not
affect the other parts of our library. One can choose other parser
combinators like Parsec, in cases that the performance and supporting
of left-recursion are not major concerns. A different library can even build a new
\name with fancy features or higher efficiency.
\end{comment}



\paragraph{\name} Our library is constructed by only around twenty lines of code. We have wrapped up the type of parsers
to make them modular and extensible, and we use our custom combinator \lstinline{<|>} for alternative composition of those
modular ``open parsers'' with longest match, built on \lstinline{|||}. Table~\ref{tab:parser} shows the API that \name provides for modular parsing.

\subsection{The Parsing Expression Problem}\label{subsec:overview-problem}
%\huang{done, added the attempt/failure/reason of extending conventional parsers}\bruno{You are not motivating the problem! You are going straight to
%  the solution without pointing out what the problem is first. What
%  you need to do is: First show what happens with conventional
%  parsers: at some point, if you add extensions the recursive calls
%  will be wrong. Then you show (in the next section) the solution:
% use delegation/open recursion.}

%\huang{partly done, only extend a new language construct in the example, how about leaving extension of new operations in the OA subsection?}\bruno{I think we need to set up a challenge here, similar to the challenge of
%  the expression problem. The challenge should be like. Build a parser
%for a simple expression language, then extend the language with both
%a new language construct and a new operation. This section will show
%how we can do that using traditional parsers, but without modular
%type-safety and separate compilation. The remaining sections will show
%that the techniques introduced by us, enable us to solve those two challenges.}

In the following text we are going to illustrate the problem that motivates our work.
Typical parsers defined by parser combinators follow the grammar
structure, they parse an input to build a corresponding AST. If the grammar is extended
with a new alternative, the corresponding parser has to be changed as
well. Thus the traditional style of developing parsers is not
extensible, and it is at odds with object-oriented programming ASTs,
which support the easy addition of new alternative classes. We
illustrate this with a simple expression language and extensions.

Suppose we want to parse a simple language of literals and
additions. The concrete syntax is as follows:

\setlength{\grammarindent}{5em}
\begin{grammar}
<expr> ::= <int>
    \alt <expr> `+' <expr>
\end{grammar}
%\alt `(' <expr> `)'

This time we allow both parts of an addition to be expressions.
It is straightforward to model ASTs by inheritance and write corresponding parsers for all cases:
%\huang{This is the first time to demonstrate code in this paper. Readers may not know what those combinators/types are. Refer to the library docs here? move the 'scala parsing library' section to the beginning as 'background'?}

\lstinputlisting[linerange=8-24]{../Scala/Parser/src/PaperCode/Overview/Overview.scala}% APPLY:linerange=OVERVIEW_SIMPLE_EXPR

\noindent Note that we use \lstinline{Parser} as a type synonym for \lstinline{PackratParser} in the rest of paper. As the combination of \inlinecode{pVar}, \inlinecode{pApp}, \inlinecode{pExpr} can parse expressions like \lstinline{"1+2"} correctly. At this point, one would like such code to be extensible in two dimensions, for example:
\begin{itemize}
\item \textbf{Challenge 1}: adding a new case (or rather, a new construct) to \lstinline{Expr};
\item \textbf{Challenge 2}: adding a new operation to \lstinline{Expr}.
\end{itemize}

\paragraph{Attempt to Extend the Parser} Now we firstly consider challenge 1, namely we are extending the syntax as well as the parser. Hence we introduce variables as a new case.

\setlength{\grammarindent}{5em}
\begin{grammar}
<expr> ::= ...
   \alt <ident>
\end{grammar}

The corresponding AST is extended as below.

\lstinputlisting[linerange=28-30]{../Scala/Parser/src/PaperCode/Overview/Overview.scala}% APPLY:linerange=OVERVIEW_SIMPLE_LAM

Since we already have the parser for literals and additions, we would like to build the new parser by reusing the old one. So we compose \inlinecode{pVar}, which parses variables, with the old parser. \inlinecode{pExtExpr} is the new function to parse expressions.

\lstinputlisting[linerange=34-37]{../Scala/Parser/src/PaperCode/Overview/Overview.scala}% APPLY:linerange=OVERVIEW_SIMPLE_EXT

Unfortunately, this extended parser does not work properly to parse all possible expressions defined by the new grammar. For example, it fails to parse \inlinecode{"1 + x"} which is obviously valid.

\paragraph{Problem: Hard-coded Recursive Calls} The critical problem of extending parsers directly is that the recursive calls in old parsers are hard-coded. Specifically, \inlinecode{pAdd} makes two recursive calls to parse two sub-expressions around \lstinline{"+"}. Before the extension, we implemented it by using \inlinecode{pExpr} for those recursive calls. It worked fine at that time because \inlinecode{pExpr} covers all cases of the old grammar. However, after the extension of variables, the proper function for such recursive calls should be \inlinecode{pExtExpr} instead of \inlinecode{pExpr}, because the new function \inlinecode{pExtExpr} includes the new extension.

That is the reason why the extended parser fails to parse some valid expressions such as \inlinecode{"1 + x"}. To resolve this issue, \inlinecode{pAdd} needs to be aware of the change of grammar. There are some possible solutions:

\begin{itemize}
    \item Keep the old code, rewrite the non-extensible function \inlinecode{pAdd}. \\Separate compilation is obtained but code reuse is lost, because every function may contain such recursive calls.
    \item Modify the old code, correct the recursive calls by proper functions. \\We can avoid duplication for code reuse, but separate compilation is sacrificed because of modification on the existing code.
    \item ??? \huang{third one? use dynamic languages?}
\end{itemize}

Because of the trade-off, neither of them are satisfying. The challenge of building semantically modular parsers requires fundamental change of the parser structure. We will introduce our solution in the next sections.

\subsection{Delegation-Based Parsing}\label{subsec:overview-delegation}

Hard-coded recursive calls prevent parsers from extensions.
This problem can be solved using delegation, which can be encoded with
\textit{open recursion}. The idea is simple: instead of making direct
recursive calls, an additional argument, that abstracts over the
recursive call, is passed to the parsers. This technique enables the
development of parsers that support OO-style extensibility of ASTs.

\paragraph{Open Parsing} Consider the expression language of only literals and additions in the previous section. The parser can be rewritten as follows:

\lstinputlisting[linerange=58-68]{../Scala/Parser/src/PaperCode/Overview/Overview.scala}% APPLY:linerange=OVERVIEW_OPEN_BASE

According to the definition of type synonym \inlinecode{Open[T]},
every parsing function takes a parser of \inlinecode{Expr} as a
parameter, namely \inlinecode{self}. This parameter \inlinecode{self}
represents \emph{the parser} of expressions, which is dynamiclly
explained by the argument. Using such an abstract ``self-reference'' provides
extensibility to parsers, because the recursive calls are not
hard-coded here --- they are dynamic and can be changed corresponding
to the grammar!
We take \inlinecode{pAdd} as an example again. It uses
\inlinecode{self} instead of hard-coded \inlinecode{pExpr} for
recursive parsing. Depending on the real argument, \inlinecode{self}
can be a parser which covers only literals and additions, or a
parser which also supports variables.

\paragraph{Client Code} Since the type of parsing functions is
changed, we can not apply them directly. A \inlinecode{fix} function, which is the
the standard \textit{fixpoint combinator}, is used to `close' the open
recursion. After that, it can be used as an ordinary parser.
The client code below demonstrates the usage of new parsers.

%\huang{done}\bruno{Too much detail is being given here about open
%  recursion. In Section 2 we should talk only about \emph{how} to use
%open recursion, and not how open recursion is implemented. We
%can summarize, for example the API related to open recursion.
%Section 4 is where the implementation and detailed explanation
%about open recursion should come.
%}

\lstinputlisting[linerange=73-77]{../Scala/Parser/src/PaperCode/Overview/Overview.scala}% APPLY:linerange=OVERVIEW_OPEN_USE

%\huang{done}\bruno{Please polish up code. You probably want to consistently use
%the variable name ``self'' whenever you want to refer to the whole
%parser (instead of ``e'' that you use at the moment). Also you should
%use ``Open'' (which you currently call ``Fix'') instead of using the
%longwinded ``(=> PackratParser[Expr]) => PackratParser[Expr]''}
%
%\huang{done}\bruno{Also, for consistency, why isn't ``pVar'' open? I.e. using a
%  self reference as well? I know that it is not recursive, but giving
%  it a different treatment makes it more confusing for users.}
%
%\huang{done}\bruno{You should use a more OO approach in the example.
%Rather than case classes show an Expr trait with pretty printing.
%This will enable you to talk about the extensibility and object
%algebras better later on.
%}

\paragraph{Extensibility} Similarly, we extend the grammar by adding variables as a new case. The new parser also extends the old one by adding \inlinecode{pVar} on it. Notice that the old code is not touched, hence separate compilation is obtained.

\lstinputlisting[linerange=82-85]{../Scala/Parser/src/PaperCode/Overview/Overview.scala}% APPLY:linerange=OVERVIEW_OPEN_EXT

\haoyuan{Code without combinators?}

All recursive calls of parsing `an expression' are realized via the explicit parameter \inlinecode{self}. Once the \inlinecode{fix} function is applied, these calls will be updated appropriately. Parsing functions such as \inlinecode{pAdd} do not need to be rewritten. As a consequence, this parser recognizes all valid expressions of the new grammar, including \inlinecode{"1 + x"} which cannot be parsed previously.

\lstinputlisting[linerange=91-91]{../Scala/Parser/src/PaperCode/Overview/Overview.scala}% APPLY:linerange=OVERVIEW_OPEN_EXT_USE

As we demonstrated, delegation encoded by open recursion is the key technique to obtain semantic modularity. It enables type-safe code reuse and separate compilation in our parsers. We will discuss this topic further in Section \ref{sec:openandparsing}.

\subsection{Object Algebras for full Extensibility}\label{subsec:overview-oa}

Although delegation enables OO extensibility, the use of an OO class
hierarchy makes the addition of new operations over the AST
problematic. Modification on existing code breaks the modularity. This
refers to the famous \textit{Expression Problem} []. For challenge 2, suppose now we want to
support evaluation on expressions, in Scala one attempt would be extending \lstinline{Expr} with
evaluation:

\lstinputlisting[linerange=111-111]{../Scala/Parser/src/PaperCode/Overview/Overview.scala}% APPLY:linerange=OVERVIEW_ATTEMPT_EXPRWITHEVAL
But then the programmer has to define new classes for literals and additions that extend old ones and \lstinline{EvalExpr}. Specifically,
the critical point is that existing parsing code only generates \lstinline{Expr} objects with pretty printing, so modification on parsing is again required.


In contrast, Object Algebras~\cite{Oliveira2012} enable us to solve this problem, as it separates data variants and
operations, to
offer high flexibility in the choice of operations to be performed
over the AST. It also makes parsing with multiple sorts of syntax easier.

\paragraph{Parsing with Object Algebras} Using Object Algebras, the abstract syntax of the expression language is defined as below.

\lstinputlisting[linerange=8-11]{../Scala/Parser/src/PaperCode/Overview/OA.scala}% APPLY:linerange=OVERVIEW_OA_ALG

Then we are able to define operations over the syntax in a modular way. For instance, pretty printing operation can be realized as:

\lstinputlisting[linerange=15-18]{../Scala/Parser/src/PaperCode/Overview/OA.scala}% APPLY:linerange=OVERVIEW_OA_PRINT

And also parser for it as below. Notice the parsing function \inlinecode{pExpr} now takes an argument of type \inlinecode{ExprAlg[E]}, which means it accepts any instance of \inlinecode{ExprAlg}. Such an instance can for example be \lstinline{Print}, which takes charge of operations on expressions, and parsing code only does delegation.

\lstinputlisting[linerange=22-27]{../Scala/Parser/src/PaperCode/Overview/OA.scala}% APPLY:linerange=OVERVIEW_OA_PARSER

\haoyuan{I'm trying to avoid using terminology like algebra and algebra interface.}

\paragraph{Extensibility of Syntax} Following previous examples, the code below shows how to extend the language with variables.

\lstinputlisting[linerange=31-44]{../Scala/Parser/src/PaperCode/Overview/OA.scala}% APPLY:linerange=OVERVIEW_OA_EXT
Note that we use the new combinator \lstinline{<|>} defined in our library, to compose two parsing functions into one. The function \lstinline{pExtExpr} has the compound type \lstinline{ExprAlg[E] with VarAlg[E]} in its argument, where two language ASTs are combined to represent the new language.

To use the parser, we must provide an algebra instance as the operation to construct the parsing results. In the code below, we use the combination of \lstinline{Print} and \lstinline{PrintVar}, so that the parsing result is a pretty printing of the AST.

\lstinputlisting[linerange=53-58]{../Scala/Parser/src/PaperCode/Overview/OA.scala}% APPLY:linerange=OVERVIEW_OA_USE

\paragraph{Extensibility of Operations} With Object Algebras, operations over ASTs can also be extended in a modular way. Here is an example of collecting free variables from an expression. We can feed this operation to the parser and obtain a set of free variables.

\lstinputlisting[linerange=72-78]{../Scala/Parser/src/PaperCode/Overview/OA.scala}% APPLY:linerange=OVERVIEW_OA_EXT_OP

\haoyuan{I think in our library language ASTs are composed using intersection, not inheritance.}

\paragraph{Multiple Sorts of Syntax} Another advantage of using Object Algebras is that it supports multiple sorts of syntax easily. In several cases, we want to divide the syntactic elements into some groups. For example, the grammar below has two sorts, which are expressions and types.

\begin{tabular}{m{0.45\linewidth}m{0.45\linewidth}}
\setlength{\grammarindent}{5em}
\begin{grammar}
<type> ::= `int' \alt <type> `->' <type>
\end{grammar}
&
\setlength{\grammarindent}{5em}
\begin{grammar}
<expr> ::=  `\\' <ident> `:' <type> `.' <expr>
\end{grammar}
\end{tabular}

Using Object Algebras, we can easily distinguish them just by adding an extra type parameter. The abstract syntax is
presented below:

\lstinputlisting[linerange=63-67]{../Scala/Parser/src/PaperCode/Overview/OA.scala}% APPLY:linerange=OVERVIEW_OA_MULTI_SYNTAX
In the next sections, we will discuss them with more details.

