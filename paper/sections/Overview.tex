\section{Overview}\label{sec:overview}

\subsection{The Choice of Parsing Techniques}\label{subsec:overview-parsing}

Parsing techniques have been heavily studied over the years, especially for context-free grammars and its subsets. However, the choice of parsing techniques is not a minor issue in a modular setting. To achieve type-safe modularity, the parsers must be able to be extended and composed, and different parsing techniques have different suitability for that.

Although every parsing algorithm can be implemented by hand in principle, some of them are not friendly for that. A \textit{parser generator} is a tool to help users generate parsers automatically or semi-automatically from a given grammar. There is no restriction on the algorithm, while most of them adopts table-based LL and LR parsing algorithms.

\huang{a paragraph here, refer to related work section, discuss previous works of modular parsing using parser generators and its drawbacks}

Comparing with the parser generators, a \textit{parser combinator} takes several parsers and produce a new parser as its output. It is popular in functional programming, where the parsers are represented by functions and parser combinators are higher-order functions accepts them.

Parser combinators are very suitable for our purpose, because of two reasons. Firstly, they are naturally modular. The manner of using them is to write small parsers and use combinators to composed them together. The construction procedure is explicit and fully controlled by the programmer. Secondly, each parser combinator is represented by a piece of code, and also are the parsers it takes. Thus in a statically typed programming language they can be type-checked during compile time.

Parser combinators adopt top-down, recursive descent parsing, which uses backtracking to search through the possible branches. However, simple backtracking parser combinators such as the famous library Parsec in Haskell, have some drawbacks. One is that they cannot support left-recursive grammars. The common solution is to rewrite a left-recursive grammar into an equivalent one, so called \textit{left-recursion elimination}. This solution requires information of the whole grammar, so that it cannot be applied in a modular setting. Because the grammar may be extended in the future, essentially we only have parts of the grammar. Another drawback is performance. Take Parsec as an example, its choice combinator only tries the second alternative if the first fails without any token consumption. If two alternatives have a same non-empty prefix, an auxiliary function \lstinline{try} must be added to backtrack. However, if we want to extend our parsers later, we should always consider the worst case in which all alternatives share common prefixes. Then we need to add \lstinline{try} for all the branches, which results worst case exponential time complexity.

Beyond the simple backtracking one, several advanced parser combinators were studied to resolve those issues. One of them is Packrat parsers, which is our choice. The details of Packrat parser are beyond the scope of this paper. In brief, Packrat parsers use memorization to record the result of applying each parser at each position of the input, so that repeated computation is eliminated, and it supports left-recursive grammars. All of these properties are very suitable for modularity, thus we use Packrat parsers as the underlying parsing technique. In section \ref{sec:packratparsers}, we will talk about the Packrat parsing library implemented in Scala, which we use.

It is worth mentioning that the choice of parser combinators will not affect the other parts of our library. One can choose other parser combinators like Parsec, in cases that the performance and supporting of left-recursion are not major concerns.

\subsection{Modular Parsers, the First Look}\label{subsec:overview-firstlook}

In this section we start demonstrating how to write modular parsers. Suppose we want to parse a simple language of variables and applications.

\begin{lstlisting}[language=PlainCode]
Expr := Var String | App Expr Expr
\end{lstlisting}

The abstract syntax can be defined by Scala's case classes, and then we write parsers for the two cases \lstinline{Var} and \lstinline{App}.

\begin{lstlisting}
abstract class Expr
case class Var(x: String) extends Expr
case class App(e1: Expr, e2: Expr) extends Expr

val pVar: PackratParser[Expr] = ident ^^ Var

val pApp: (=> PackratParser[Expr]) => PackratParser[Expr] =
  e => e ~ e ^^ { case e1 ~ e2 => App(e1, e2) }
\end{lstlisting}

Some structures are imported from the Scala Packrat parsing library, such as the combinator \lstinline{^^}. They will be discussed in later sections, so that readers could only focus on the type of parsers at the first reading.

\lstinline{pVar} for parsing variables is straight forward. It parses a single identifier, and its type \lstinline{PackratParser[Expr]} indicates the result is an \lstinline{Expr}.

The type of \lstinline{pApp} is different. It takes a parser of \lstinline{Expr} as an argument, and use it to parse two consecutive expressions as an application. This argument \lstinline{e} represents the parser of \emph{the whole expression}. In this particular case, it is in fact the combination of \lstinline{pVar} and \lstinline{pApp}. We can replace it by \lstinline{pVar | pApp} and the code still works. However, using an abstract argument provides extensibility to the parser. Because once the abstract syntax is extended later, the parser of the whole expression will change correspondingly. Then we have to edit existing code if it is hard-coded. The parameterization technique used in \lstinline{pApp} is called \textit{open recursion}, which is discussed in section \ref{sec:openandparsing}.

We can use a trait to glue them together, and define \lstinline{pVarApp} as a combination of the two parsers. A type synonym \lstinline{Fix} is used to shorten the types.

\begin{lstlisting}
type Fix[T] = (=>T) => T

trait ExprParser {
  lexical.delimiters += ("(", ")")

  val pVar: PackratParser[Expr] =
    ident ^^ Var
  val pApp: Fix[PackratParser[Expr]] =
    e => e ~ e ^^ { case e1 ~ e2 => App(e1, e2) }
  val pVarApp: Fix[PackratParser[Expr]] =
    e => pApp(e) | pVar | "(" ~> e <~ ")"
}
\end{lstlisting}

Finally, we are able to parse \lstinline{Expr} frome strings as shown in the code below. The \lstinline{fix} function here is just the standard \textit{fixpoint}, it is explained in section \ref{subsec:openrecursion}.

\begin{lstlisting}
def parse[E](p: Fix[PackratParser[E]])(inp: String): E = {
  val t = phrase(fix(p))(new lexical.Scanner(inp))
  if (t.successful) t.get else scala.sys.error(t.toString)
}

println(parse(new ExprParser {}.pVarApp)("x y"))
\end{lstlisting}

It will print the AST as \lstinline{App(Var(x),Var(y))}.

\subsection{Extend and Reuse Parsers}\label{subsec:overview-extend}

We have done our modular parser, and it behaves just in a normal way. To demonstrate the advantages of writing modular parsers, we extend the language to add lambda abstractions as a new case of expressions. The language then becomes the famous \textit{untyped lambda calculus}.

\begin{lstlisting}[language=PlainCode]
Expr := Var String | App Expr Expr | Lam String Expr
\end{lstlisting}

With Scala's case classes, extending the abstract syntax \lstinline{Expr} is easy.

\begin{lstlisting}
case class Lam(x: String, e: Expr) extends Expr
\end{lstlisting}

Since we already have the parser for variables and applications, we want to reuse it and build a new parser by extending it. It is just what the code below does. Notice that the old code is not touched, hence separate compilation is obtained.

\begin{lstlisting}
trait LambdaParser extends ExprParser {
  lexical.delimiters += ("\\", ".")

  val pLam: Fix[PackratParser[Expr]] =
    e => "\\" ~> ident ~ ("." ~> e) ^^ { case x ~ b => Lam(x, b) }
  val pVarAppLam: Fix[PackratParser[Expr]] =
    e => pLam(e) | pVarApp(e)
}
\end{lstlisting}

In the new parser \lstinline{LambdaParser} extended from the old one, we write a new parsing function \lstinline{pLam} for the new case lambda abstraction. And compose it with \lstinline{pVarApp}, which we already have in the old parser \lstinline{ExprParser}. Open recursion is critical to achieve such type-safe compositions, because wherever we refer to the parser of the whole expression, it is updated to cover all of the three case we have now.

\begin{lstlisting}
println(parse(new LambdaParser {}.pVarAppLam)("(\\x.x) y"))
\end{lstlisting}

The code above will print \lstinline{App(Lam(x,Var(x)),Var(y))} from parsing \lstinline{"(\\x.x)} \lstinline{y"}.

\subsection{Object Algebras and More}\label{subsec:overview-oa}

Instead of define the abstract syntax using Scala's case classes, we can use \textit{Object Algebras} for more extensibility. Object Algebras is a technique to solve the \textit{Expression Problem}, providing the possibility of extending both data variants and operations over them. It will be further discussed in section \ref{sec:algebrasandparsing}.

Using Object Algebras, the abstract syntax of the language of variables and applications is defined as below.

\begin{lstlisting}
trait Alg[E] {
  def Var(x: String): E
  def App(e1: E, e2: E): E
}
\end{lstlisting}

Then we are able to define operations over the syntax in an extensible way. Here we write a pretty printing operation for this language.

\begin{lstlisting}
trait Print extends Alg[String] {
  def Var(x: String) = x
  def App(e1: String, e2: String) = "(" + e1 + " " + e2 + ")"
}
\end{lstlisting}

And also parser for it as below. Notice the parsing function \lstinline{pVarApp} takes an argument of type \lstinline{Alg[E]}, that means it accepts any instance of the algebra interface \lstinline{Alg}.

\begin{lstlisting}
trait Parser[E] {
  lexical.delimiters += ("(", ")")

  val pVarApp: Alg[E] => Fix[PackratParser[E]] = alg => e =>
    e ~ e ^^ { case e1 ~ e2 => alg.App(e1, e2) } | ident ^^ alg.Var | "(" ~> e <~ ")"
}
\end{lstlisting}

We glue them together by defining an object. It actually becomes a \textit{language component} that represents a specific language feature.

\begin{lstlisting}
object VarApp {
  trait Alg[E] {..}
  trait Print extends Alg[String] {..}
  trait Parser[E] {..}
}
\end{lstlisting}

To use the parser, we must provide an algebra instance as the operation to construct the parsing result. As shown in the code below, we feed the pretty printing operation \lstinline{VarApp.Print} to the generic \lstinline{parse} function. It will print \lstinline{(x y)} as the result.

\begin{lstlisting}
def parseWithAlg[E](inp: String)(alg: VarApp.Alg[E]): E = {
  val p = new VarApp.Parser[E] {}.pVarApp(alg)
  parse[E](p)(inp)
}

println(parseWithAlg("x y")(new VarApp.Print{}))
\end{lstlisting}

With Object Algebras, we can extend all the stuff, including abstract syntax, operations, and parsers. The code below extend the language to support lambda abstraction.

\begin{lstlisting}
object Lambda {
  trait Alg[E] extends VarApp.Alg[E] {
    def Lam(x: String, e: E): E
  }

  trait Print extends Alg[String] with VarApp.Print {
    def Lam(x: String, e: String) = "\\" + x + "." + e
  }

  trait Parser[E] extends VarApp.Parser[E] {
    lexical.delimiters += ("\\", ".")

    val pLam: Alg[E] => Fix[PackratParser[E]] = alg => e =>
      ("\\" ~> lcid) ~ ("." ~> e) ^^ { case x ~ e0 => alg.Lam(x, e0) }
    val pVarAppLam: Alg[E] => Fix[PackratParser[E]] =
      pVarApp | pLam
  }
}
\end{lstlisting}

For easily combining the parsers using Object Algebras as the representation of abstract syntax, we have a special combinator \huang{we need to rename our combinator} defined in our library.

In addition to make extending operations possible, another advantage of using Object Algebras is that it supports multiple sorts of syntax. For example, if our language has not only expressions but also types, we can easily distinguish them in the abstract syntax by an extra type parameter. This topic will be discussed in section \ref{subsec:differentsyntax}.

\begin{lstlisting}
trait TypedLambda[E, T] extends VarApp.Alg[E] {
  def Lam(x: String, t: T, e: E): E
  def IntType(): T
  def BoolType(): T
  def ArrowType(a: T, b: T): T
}
\end{lstlisting}



% \begin{itemize}
% \item Choosing the Parsing Technology
%     \begin{itemize}
%     \item Parser Generators : why not?
%         \begin{itemize}
%             \item Not type-safe
%             \item No modular type-checking
%             \item Not modular or no separate compilation (but we need to mention lots of work on extensible parsing here: example Language Workbenches; Rats)
%         \end{itemize}
%     \item Parser Combinators
%         \begin{itemize}
%         \item Backtracking parsers (Parsec)
%             \begin{itemize}
%             \item Need to remove left recursion (Problem: Transformation is not modular; if we do not know the full grammar then cannot be done)
%             \item Need try/backtracking (Problem: Since we do not know the full set of rules in a modular setting, we have to assume worst case scenario and add redundant backtracking. )
%             \item Mention some possible workarounds (there may be some but they still have issues)
%             \end{itemize}
%         \item (Non)-Backtracking/Packrat Parsers (Works well in a modular setting) (find a good name for this type of parsers?)
%         \end{itemize}
%     \end{itemize}
% \item Adapting Parser Combinators for modularity
%     \begin{itemize}
%     \item Using Object Algebras
%     \item Using Open Recursion
%     \item Using new modular parser combinators (Library: new alternative combinator, for example)
%     \end{itemize}
% \item Small example
%     \begin{itemize}
%     \item small example of a modular parser using our technique
%     \item show also the same example without modularity and write a detailed comparison
%     \item Lambda Calculus is a good candidate for the example
%     \item Show a small extension (adding plus and numeric literals)
%     \end{itemize}
% \end{itemize}
