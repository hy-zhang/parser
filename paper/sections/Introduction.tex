\section{Introduction}\label{sec:introduction}
 
The quest for improved modularity, variability and extensibility of
programs has been going on since the early days of Software
Engineering~\cite{McIlroy68}. Modern Programming Languages (PLs) enable a certain
degree of modularity, but they have limitations as illustrated by
well-known problems such as the Expression Problem~\cite{wadler1998expression}. The
Expression Problem refers to the difficulty of writing data
abstractions that can be easily extended with both new operations and
new data variants. Traditionally the kinds of data abstraction found
in functional languages can be extended with new operations, but
adding new data variants is difficult. The traditional object-oriented
approach to data abstraction facilitates adding new data variants
(classes), while adding new operations is more difficult.

\begin{comment}
A reason why a solution to the Expression Problem is important in
practice is that it is necessary for the development of
\emph{Software-Product Lines} (SPLs)~\cite{}. A software-product line
is a reusable set of components, which can be combined in multiple ways
to obtain different programs. Programming languages offer a concrete
example for SPLs. A SPL for programming languages would allow us to
model various typical operations of programming languages (such as
evaluation, compilation, or parsing) for various different language
constructs (such as binding, arithmetic, conditional or loops)
independently and separately. For example, evaluation components could be defined
independently for binding and arithmetic constructs. If the language
to be implemented is the pure lambda calculus, only evaluation of
binding constructs is necessary. However, more realistic programming
languages will include arithmetic constructs, and will require 
evaluation for such constructs as well. In this case 
both the component for evaluation of binders and arithmetic 
expressions can be combined to implement the desired functionality.
\end{comment}

\begin{comment}
Most programming languages share alot of features in
common. 

For example, most languages have language constructs for:
binding (such as variables, functions, and function applications);
basic arithmetic operations; basic logic and conditional operations;
loops; as well as various other features. For each language construct,
various operations (such as evaluation, compilation, or parsing) need
to be implemented. It is reasonable to wonder whether we can simply
implement those features independently of a particular implementation
of a programming language. Evaluation could be defined independently 
for binding and arithmetic constructs. If the language to be
implemented is the pure lambda calculus, only evaluation of binding 
constructs is necessary. Thus only the component that implements 
evaluation for binding needs to be used in such an implementation.
However, more realistic programming languages 
will include arithmetic constructs, and will require an evaluation
function for those. 


Then it would be possible to \emph{reuse}
some of those features in \emph{multiple} different implementations of
programming languages. Essentially, this would enable a SPL for
programming languages, where all

A solution to the Expression Problem could ena



A concrete 
example that illustrates this issue is 
\end{comment}

To address the modularity limitations of Programming Languages several
different approaches have been proposed in the past. Existing
approaches can be broadly divided into two categories:
\emph{syntactic} or \emph{semantic} modularization
techniques. Syntactic modularization techniques are quite popular in
practice, due to their simplicity of implementation and use. 
Examples include many tools for developing Software-Product
Lines~\cite{}, some Language Workbenches~\cite{}, or extensible parser
generators~\cite{}.  Most syntactic approaches employ textual
composition techniques such as \emph{superimposition}~\cite{} to
enable the development modular program features. Such textual
composition techniques collect the code for multiple features and
merge it together when a concrete combination of features is needed
for a particular program. As Kastner et. al~\cite{Kastner11road} note, the typical
drawback of such techniques is that
``\emph{most feature-oriented implementation mechanisms lack proper
  interfaces and support neither modular type checking nor separate
  compilation}''. 

Syntactic modularization techniques have also been applied to the
problem of \emph{extensible parsing}. There are several approaches
that enable the development of \emph{syntactically} modular parsers or
grammars. Many parser
generators~\cite{antlr1995,Grimm2006,Gouseti2014,Warth2016} support
modular grammars. For instance, \textit{Rats!}~\cite{Grimm2006} has
its own module system for the collection of grammars.  Extensible
compilers like JastAdd~\cite{Ekman2007} and
Polyglot~\cite{Nystrom2003} also support extensible parsing, but this
is mostly done ultimately resorting to standard (non-modular) parser
generators. Various techniques supporting languages that can extend
their own syntax, such as SugarJ~\cite{Erdweg2011}, also offer a form
of extensible parsing. However these syntactic approaches do not
support separate compilation and/or modular type-checking of parsing
code either.

Semantic modularization techniques go one step further in terms of modularity,
and also enable components or features to be modularly type-checked
and separately compiled. Modular type-checking and separate
compilation are desirable properties to have from a software
engineering point-of-view. Modular type-checking can report errors 
earlier and in terms of the modular code programmers have written 
in the first place. Separate compilation avoids global compilation
steps, which can be very costly. Furthermore semantic modularization 
enables the composition of compiled binaries as well as ensuring the 
type-safety of the code composed of multiple components. Examples of semantic modularization techniques 
include various approaches to \emph{family polymorphism}~\cite{ernst01FP},
\emph{virtual classes}~\cite{Ernst:2006}, as 
well as several other techniques for solving the Expression
Problem~\cite{Oliveira:2012}\bruno{more here; yanlin; Torgersen; Odersky...}. 

Semantic modularization techniques are less widely used in practice
than syntactic techniques. This is partly due to the need for more
sophisticated type systems, which are not available in mainstream
languages and may require more knowledge from users. However, recently
several lightweight modularization techniques have been shown to work
in mainstream programming languages like Java or Scala. Object
Algebras~\cite{Oliveira:2012} are one such technique, which works in
Java-like languages and uses simple generics only. So far research on
semantic modularization techniques have focused on operations that
\emph{traverse} or or \emph{process} extensible datastructures, such
as ASTs. Indeed many documented applications of semantic
modularization techniques focus on modularizing various aspects of PL
implementations.  However, as far as we know there is little work on
operations that build/produce ASTs.  In particular the problem of how
to modularize parsing has not been studied in semantic modularization
approaches. This is a shame because parsing is a fundamental part of
PL implementations, and it ought to be modularized as well.

%\paragraph{Modular and Extensible Parsing}

This paper investigates presents a technique for doing semantically
modular parsing.  That is, our approach not only allows complete
parsers to be built out of modular parsing components, but also enables
those parsing components to be \emph{modularly type-checked} and
\emph{separately compiled}. In developing our techniques we encontered 
two different classes of challenges:

\begin{itemize}

\item {\bf Algorithmic challenges:} A first challenge was todo with
  the parsing algorithms themselves. Since many parsing formalisms
  were not designed with extensibility in mind, some of the employed 
  techniques were non-modular, or performed poorly in a modular setting. 

\item {\bf Typing and Reusability Challenges:} The second class of
  challenges were problems related to modularity, reusability and
  typing.

\end{itemize}

\name is built on top of a Packrat parsing
library, but adds new parsing combinators to enable modular
parsing. The new parsing combinators employ \emph{delegation-based}
techniques and \emph{Object Algebras} to support extensibility. The
choice of Packrat parsing over other parsing techniques turns out to
be important for achieving performance in a modular
setting. \bruno{left recursion, and backtracking removal.}


  By analising the \emph{full} grammar it is possible to remove
  backtracking, which would otherwise increase parsing times. Many
  parsing combinator libraries routinely use backtracting elimination
  to achieve performance. However, in a modular setting this technique
  cannot be used, because the full grammar is not known. Thus we have
  to be very conservative at eliminating backtracting. Unfortunatelly,
  this has a severe impact on performance.

  To evaluate \name we conduct a case study based on the ``Types and
  Programming Languages'' (TAPL) interpreters.  The case study shows
  that \name is effective at reusing parsing code from existing
  interpreters, and the total parsing code is 60\% shorter than the
  non-modular parsing code.\bruno{comment on the efficiency}

In summary our contributions are:

\begin{itemize}

\item {\name:} A parser combinator library that allows the development 
of modular parser. The library uses \emph{delegation} and
\emph{Object-Algebras} to achieve modularity and extensibility.

\item {{\bf A Parsing Technique for OO ASTs:}} A simplified version of
  our technique also enables parsing OO-style ASTs, where new language
  constructs can be easily added.

\item {{\bf Limitations of existing Parser Combinator Techniques:}}
\bruno{Improve and write something here.}

\item {{\bf TAPL case study:}} We conduct a case study with 18 interpreters
  from the TAPL book. The case study show the effectiveness of modular 
  parsing in terms of reuse.

\end{itemize}


\haoyuan{I suggest this part to be moved to Introduction, and only discuss why Packrat is selected among
different parser combinators in Overview.}

\begin{comment}
Although there are many parsing techniques, not all of them are
suitable for type-safe modular parsing. In particular there are many
techniques which fail to provide modular type-checking and separate
compilation. Moreover, even if modular type-checking and separate
compilation are supported, efficiency is another
concern. A parsing technique should have low overhead when applied
in a modular setting. In the remaider of this section, we eliminate
various techniques that fail to satisfy our requirements, and argue
that that Packrat parsing~\cite{Ford2002} is a suitable candidate for
type-safe modular parsing.

\paragraph{Parser Generators} The most widely use tools for parsing
are parser generators. Parser generators help users generate parsers automatically or
semi-automatically from a given grammar. There is no restriction on
the algorithm, while most of them adopts table-based LL~\cite{lewis1968syntax} and LR~\cite{knuth1965translation} parsing
algorithms.
Although efficient, the main drawback of parser generators is that they do not support
modular type-checking and separate compilation.

Modular parsing based on parser generators is supported by many libraries~\cite{antlr1995,Grimm2006,Gouseti2014,Warth2016}. Users can separate the syntax definition and related parsing code into reusable components. Then the corresponding parsers are built by their library utilities. For example, NOA~\cite{Gouseti2014} uses Java annotation processing to collect grammar information, and then generates ANTLR4 parsers. However, such generation procedure requires a whole compilation after the collection of all grammar pieces. Once the grammar changed, even slightly, grammar information must be re-collected and the parser must be re-generated. Hence those libraries only have syntactic modularity.

Generating parsers often requires full information of grammars, thus semantic modularity is difficult to achieve in this way.

\paragraph{Parser Combinators}
Comparing with the parser generators, a \textit{parser combinator}~\cite{burge1975,Wadler1985}
takes several parsers and produce a new parser as its output. Parser combinators are
popular in functional programming, where the parsers are represented
by functions and parser combinators are higher-order functions accepts
them.

At a first look, parser combinators are very suitable for our purpose, because of two
reasons. Firstly, they are naturally modular. The manner of using them
is to write small parsers and use combinators to composed them
together. The construction procedure is explicit and fully controlled
by the programmer. Secondly, each parser combinator is represented by
a piece of code, and also are the parsers it takes. Thus in a
statically typed programming language they can be statically
type-checked.
\end{comment}