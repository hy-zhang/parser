\section{Modular Parsing Library}\label{sec:library}

%\begin{itemize}
%\item Fixpoints library + explaining delegation with some examples
%\item Alternative combinator + others
%\item Trait Composition to do Language Composition
%\end{itemize}

In this section, we will further look into the mechanism behind our modular parsing library.
Starting from simple examples, a series of extensions and improvements are applied to illustrate
how we achieve modularity in a type-safe way.

\subsection{Open Recursion and Delegation}\label{subsec:openrecursion}

Our story begins with a single parser that only parses a free variable (i.e., a string). In Scala we use the Packrat Parsing
library, which supports lexing and direct left-recursion. To write such a parser, we need to import the library as
well as defining the datatype for which it produces.

\begin{lstlisting}
object OpenRecursion extends StandardTokenParsers with PackratParsers {
    class Expr
    class Var(x : String) extends Expr
    val pVar : PackratParser[Expr] = ident ^^ { x => new Var(x) }
    ...
}
\end{lstlisting}
Note that we are omitting lexing and demo code here. Furthermore, we would like the parser to support applications.
Not only the implementation of that parser is needed, but also its corresponding datatype: (we omit the fact that the code for below few
examples is written in the same object, namely \lstinline{OpenRecursion})
\begin{lstlisting}
class App(e1 : Expr, e2 : Expr) extends Expr
val pApp : PackratParser[Expr] = pVar ~ pVar ^^ { case e1 ~ e2 => new App(e1, e2) }
\end{lstlisting}
Such a parser \lstinline{pApp} can only parse one-layer applications like \lstinline{"x y"}. Hence we revise it using recursion:
\begin{lstlisting}
val pApp : PackratParser[Expr] =
    (pApp | pVar) ~ (pApp | pVar) ^^ { case e1 ~ e2 => new App(e1, e2) }
\end{lstlisting}
Now \lstinline{pApp} manages to parse an arbitrary number of applications like \lstinline{"x y z ..."} in a right-associative way.
Nevertheless, such an approach does not turn out to be a modular extension. The grammar we want for an expression is actually:
\begin{lstlisting}
e ::= x | e ' ' e | ...
\end{lstlisting}
Note that such an \lstinline{"e"} in the second case should not only include all existing cases, but also take all future extensions into account (the ellipsis we used above, for instance, \lstinline{e '+'} \lstinline{e}). This inspires us to use \textit{open recursion}. To define \lstinline{pApp} in a different way, we add a parameter \lstinline{p} to it, representing the explicit ``self reference'' of our whole parser, which is open to future extensions. Note that \lstinline{p} should be defined as a by-name parameter using \lstinline{"=>"}.
\begin{lstlisting}
val pApp : (=> PackratParser[Expr]) => PackratParser[Expr] =
    p => p ~ p ^^ { case e1 ~ e2 => new App(e1, e2) }
\end{lstlisting}
Similarly we redefine \lstinline{pVar} also as a function using the fixpoint \lstinline{p}. Furthermore, we combine \lstinline{pVar} and \lstinline{pApp} together using the parser combinator \lstinline{"|"} for alternative:
 \begin{lstlisting}
val pVar : (=> PackratParser[Expr]) => PackratParser[Expr] =
    p => ident ^^ { x => new Var(x) }
val pVarApp : (=> PackratParser[Expr]) => PackratParser[Expr] =
    p => pApp(p) | pVar(p)
\end{lstlisting}
But what we really want is something that has type \lstinline{PackratParser[Expr]}. In functional programming, we can use ``fix'' to get the fixpoint of a function, in this case we write \lstinline{fix(pVarApp)}, which parses an arbitrary number of applications. Such a function can easily be defined
in Scala based on its laziness:
\begin{lstlisting}
def fix[A](f : (=> A) => A) : A = { lazy val a : A = f(a); a }
\end{lstlisting}
That is the magic of open recursion: we can define as many small components as we like, and they are implemented as functions, with the help of explicit self-reference. Whenever we would like to close the recursion, simply use \lstinline{fix} for their combination. Such a process is guaranteed to terminate when we restrict the input for parsing to be finite, and we have some base cases like \lstinline{pVar}, which terminates recursion in their branches, in addition, with the help of direct left-recursion support from Packrat parsers.

Another thing which catches our attention is that, small parsers are combined using the alternative combinator. It is a matter of delegation: parsing failing at any position will try its next alternative, and for each recursion all the parsers are tried successively until one of them succeeds. It reveals its essence as a recursive descent parser. But it is quite easy and modular to use; with further extensions, they can be implemented separately and then appended to the combination of old ones.

\subsection{Parser Combinators}\label{subsec:parsercombinators}

Using Packrat parsers we obtain the access to a lot of library functions, including parser combinators. In the last subsection we introduced \lstinline{|} for alternation, which realizes delegation pattern in our parsing. Moreover, we have \lstinline{~} for sequential composition, \lstinline{rep} and \lstinline{repsep} for repetitions, \lstinline{chainl1} for left-associative grammars, and so on.

Specifically, Scala parsers have a new combinator \lstinline{|||} also for alternative but with longest match composition. Consider the example in the last subsection, where we used \lstinline{pApp(p)} \lstinline{|} \lstinline{pVar(p)} for alternation. If \lstinline{pVar} is put in the front instead, the parser cannot even parse \lstinline{"x y"}, since the first case succeeds, which unexpectedly stops parsing and discards the rest. But \lstinline{|||} can successfully parse the whole input string. It implies that using \lstinline{|||} we no longer need to worry about the order of composition, which encourages its extensibility.

On the other hand, practically parsers are defined as functions (as shown above), which means we do not apply \lstinline{|||} to them directly, but use \lstinline{|||} implement a new combinator for those functions. We will introduce it later in this paper.

\subsection{Object Algebras for Different Syntax}\label{subsec:differentsyntax}

Such extensibility becomes fragile when it comes to grammars with different syntax. Now suppose we would like to have types in the grammar. Firstly the new grammar is shown below, where the \lstinline{Int} type and lambda expression with annotation have been added:
\begin{lstlisting}
e ::= x | e ' ' e | \x:t.e
t ::= "Int"
\end{lstlisting}

We proceed to implement those parsers. An issue is that we need both a \lstinline{PackratParser[Expr]} and a \lstinline{PackratParser[Type]} in the fixpoint.
Hence we use a pair in the parameter:
\begin{lstlisting}
class Type
class Int extends Type
val pInt : (=> (PackratParser[Expr], PackratParser[Type])) => PackratParser[Type] =
    p => "Int" ^^ { _ => new Int() }

class Lam(x : String, t : Type, e : Expr) extends Expr
val pLam : (=> (PackratParser[Expr], PackratParser[Type])) => PackratParser[Expr] =
    p => ("\\" ~> ident) ~ (":" ~> p._2) ~ ("." ~> p._1)
        ^^ { case x ~ t ~ e => new Lam(x, t, e) }

val p : (=> (PackratParser[Expr], PackratParser[Type])) => (PackratParser[Expr], PackratParser[Type]) =
    p => (pVar(p._1) ||| pApp(p._1) ||| pLam(p), pInt(p))
\end{lstlisting}
The last value \lstinline{p} integrates the four single parsers defined before, so we use \lstinline{fix(p)} to
obtain the two parsers we want: one for expressions, the other for types. The parser \lstinline{fix(p)._1} parsers expressions
like \lstinline{"\x:Int.x x"} successfully. Yet meanwhile, some drawbacks of this approach come into sight. With different syntax, it
is necessary to extend the fixpoint to contain more parsers, in which case usually some structures like tuples are used,
making code tedious and less elegant. On the other hand, the modularity is quite restricted; only parsing and datatypes are extensible.
Suppose now we want to realize some behaviors on those data structures, for example pretty-printing, then whenever we introduce a new behavior,
it needs implementations in every class body, requiring existing code to be modified. At this point, Object Algebras are adopted for data structures
instead.

Object Algebras are a nice solution to the famous \textit{Expression Problem}, achieving two dimensions of extensibility (data variants and operations)
in a type-safe way. The intuition of using Object Algebras is to separate data structures from behaviors, so as to modularize the design. We can simply add new variants for the new cases in the grammar, or realize different operations on structures, without modifying existing code, and separate compilation is supported. Coincidentally, Object Algebras use generics, where the type parameters perfectly support extensible different syntax, and hence simplify the code comparatively. Below is the code using Object Algebras, where we start from \lstinline{varE} and \lstinline{appE} only, later we extend them with \lstinline{intT} and \lstinline{lamE}:
\begin{lstlisting}
trait OldAlg[E] {
    def varE(x : String) : E
    def appE(e1 : E, e2 : E) : E
}

trait OldParser[E] {
    val pE : OldAlg[E] => (=> PackratParser[E]) => PackratParser[E] = alg => p =>
        ident ^^ { x => alg.varE(x) } |||
        p ~ p ^^ { case e1 ~ e2 => alg.appE(e1, e2) }
}
\end{lstlisting}
Here \lstinline{OldAlg} is called an \textit{Object Algebra interface}, which has two constructs for the AST. Its parser is
supposed to produce a structure from an input, whereas with Object Algebras structures are implicit: an \textit{algebra}
is immediately applied to the structure and returns the result. It means such a structure that the parser generates should have
type \lstinline{"OldAlg[E] =>} \lstinline{E"} for some \lstinline{E}. In the above code, \lstinline{alg} which has type
\lstinline{OldAlg[E]} is an algebra, and appears as a parameter of \lstinline{pE}, then in the body of \lstinline{pE} the algebra
is invoked correspondingly right after parsing. Since it should be a generic algebra, the parser is enclosed by the generic trait \lstinline{OldParser}.

% more: newparser, two pretty-printers OldPretty and NewPretty, they are separated to show modularity.
% more: modify the code using List[E] and type bounds.
% more subsections: lexing, traits, operations, language composition (more extensibility)
