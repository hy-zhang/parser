\section{Case Studies}\label{sec:casestudy}


To demonstrate the utility of our modular parsing approach, we
implemented parsers of the first 18 calculi from book \textit{Types and Programming Languages} (TAPL) \cite{pierce2002types}. We compared our implementation with a non-modular implementation
we found online, which is also written in Scala and uses the same Packrat parsing library.
We counted source lines of code (SLOC) and measured execution time for both implementations.
The result suggests that our implementation saves 69\% code comparing with that non-modular one.

\subsection{Implementation}\label{subsec:implementation}

TAPL introduces several calculi from simple to complex, by gradually adding new features to syntax. These calculi are suitable for our case study for mainly two reasons. Firstly, they capture many of the language features
required in realistic programming languages, such as lambdas, records and variants. Secondly, the evolution of
calculi in the book reveals the advantages of modular representation
of abstract syntax and modular parsing, which is the key functionality
of our approach. By extracting common components from those calculi
and reusing them, we obtain considerably code reuse as shown later.

\paragraph{Extracting Language Components}
Using the pattern demonstrated in Section~\ref{subsec:language-component}, we extract
reusable components from all the calculi. Each
component, which may contain several syntactical structures,
represents a certain feature of the language. For
example, the \lstinline{VarApp} component below represents variables and
function applications, shown in Figure~\ref{fig:casestudy-varapp}.

\begin{figure}[ht]
\lstinputlisting[linerange=15-33]{../Scala/Parser/src/PaperCode/Sec6CaseStudy/Code1.scala}% APPLY:linerange=CASESTUDY_VARAPP
\caption{The \inlinecode{VarApp} component in case study.}\label{fig:casestudy-varapp}
\end{figure}

Similar as before, each component is represented by a Scala object which includes \lstinline{Alg} for the abstract syntax, \lstinline{Print} for pretty-printing, and \lstinline{Parse} for parsing.

We have some naming conventions in our code, \lstinline{E} represents
expressions, \lstinline{T} represents types and \lstinline{K}
represents kinds. They are the three sorts of syntax in our case study.
In the component \lstinline{VarApp} we only have expressions. We use some helper traits for eliminating duplicate definitions, such as \inlinecode{EParser} containing \inlinecode{pE} for parsing expressions.

\lstinputlisting[linerange=9-11]{../Scala/Parser/src/PaperCode/Sec6CaseStudy/Code1.scala}% APPLY:linerange=CASESTUDY_EPARSER

\paragraph{Composing Language Components}
Each calculus could be composed directly from components and other
calculi as needed. For example, the calculus \lstinline{Untyped} in our case study,
representing the famous untyped lambda calculus, is constructed from components \lstinline{VarApp}
and untyped lambda abstraction \lstinline{UntypedAbs}.

The code of building \lstinline{Untyped} is presented in Figure~\ref{fig:casestudy-untyped}. Note that in the parser \inlinecode{Parse}, we need to override the object algebra interface and
parsing functions accordingly.

\begin{figure}[ht]
\lstinputlisting[linerange=37-64]{../Scala/Parser/src/PaperCode/Sec6CaseStudy/Code1.scala}% APPLY:linerange=CASESTUDY_UNTYPED
\caption{Build the \inlinecode{Untyped} calculus by composing to language components.}\label{fig:casestudy-untyped}
\end{figure}

\paragraph{Demo code}
We have demo code for every calculus in order to test and evaluate our implementation.
We feed the pretty printing algebra to the parser and print out the result.
The parsing result can be changed as long as the concrete algebra is available.

\lstinputlisting[linerange=68-78]{../Scala/Parser/src/PaperCode/Sec6CaseStudy/Code1.scala}% APPLY:linerange=CASESTUDY_DEMO

\paragraph{Dependency Overview}
Figure \ref{fig:dependency} shows the
dependency of all the components and calculi in our case study. Gray
boxes are calculi and white boxes are components. An arrow starting
from box A to box B denotes that B includes and thus reuses A.

\begin{figure}
    \centering
    \includegraphics[width=\textwidth]{resources/depGraph.pdf}
    \caption{Dependency graph of all calculi and components in case study.}
    \label{fig:dependency}
\end{figure}

As shown in the graph, some components such as \lstinline{VarApp} are
created from scratch, while others such as \lstinline{Typed} are
extended from existing components. Since calculi and components have the similar signature, each calculus
can also be extended and reused directly. For example, calculus \lstinline{FullRef} extends from
calculus \lstinline{FullSimple}.

From the dependency graph, we know
that common components such as \lstinline{VarApp} are reused in
lots of calculi. Such reuse could shorten the code considerably. We
will show this advantage and exam the possible performance penalty in
a quantitative way in the next subsection.

\subsection{Comparison}\label{subsec:cs-comparison}

We compared our implementation of the parsers with an implementation
by Ilya Klyuchnikov, available online\footnote{https://github.com/ilya-klyuchnikov/tapl-scala/}.
Ilya's implementation is suitable for comparison, because it is also
written in Scala using the same parser combinator library.
Furthermore, it includes parsers of all the 18 calculi we have, but
written in a non-modular way. Thus it is not able to reuse existing
code when those calculi share common features.

The comparison is made from two aspects. First, we want to discover
the amount of code reuse using our modular parsing approach.
For this propose, we measured source lines of code (SLOC) of two implementations.
Second, we are interested to assess the performance penalty caused by modularity.
Thus we compared the execution time of parsing random expressions between two implementations.

\paragraph{Standard of Comparison}
In the SLOC comparison, all blank lines and comment lines are excluded,
and we formatted the code of both implementations to guarantee that
the length of each line does not exceed 120 characters. Furthermore,
because Ilya's implementation has extra code such as semantics,
we removed all irrelevant code and only keep abstract
syntax definition, parser and pretty printer for each calculus, to
ensure a fair comparison.

For the comparison of execution time, we built a generator to randomly
generate valid expressions of each calculus, according to the syntax. These expressions are
written to test files, one file per calculus. Each test file consists of 500
expressions randomly generated, and the size of test files varies from 20KB to 100KB.
Then we run the corresponding parser to parse the file and the pretty printer to print the result.
The average execution time of 5 runs excluding reading input file was calculated, in milliseconds.

\huang{done}\bruno{say something about what those expressions are, size, and how they were generated.}

\begin{table}
    \centering
    \begin{tabular}{|l|r|r|r|r|r|r|}
      \hline
        \multirow{2}{*}{\bfseries Calculus Name} & \multicolumn{3}{ c| }{\bfseries SLOC} & \multicolumn{3}{ c| }{\bfseries Time (ms)} \\ \cline{2-7}
        \multicolumn{1}{|c|}{} & \bfseries Ilya's & \bfseries Ours & \bfseries (+/-)\% & \bfseries Ilya's & \bfseries Ours & \bfseries (+/-)\% \\
      \hline
      \input{resources/CaseStudyTable.tex}
      \hline
    \end{tabular}
    \caption{Comparison of SLOC and execution time}
    \label{tab:comparison}
\end{table}

\paragraph{Comparison Results}
Table \ref{tab:comparison} shows results of the comparison.
The overall result is that 69.2\% of code is reduced using our
library, and our implementation is 42.7\% slower.

The good SLOC result is because of that the code of common language features
such as variables, lambda abstractions, etc., are reused lots of times in
the whole case study. We can see that in the first two calculi
\lstinline{Arith} and \lstinline{Untyped} we are not better than Ilya's
implementation, because in such two cases we do not reuse any existing
components. However in the following 16 calculi, we can reuse
language components, resulting considerably code reduction. In particular,
the calculi \inlinecode{EquiRec}, \inlinecode{Recon} and some others are only 22 lines
in our implementation, because we only compose existing codes in such cases.

To discover the reasons of slower execution time, we made some more experiments
on two possible factors which could affect the performance.
They are object algebra and the longest match alternative combinator.
We use object algebra for ASTs and the longest match alternative combinator \inlinecode{|||} for parsing,
while Ilya's implementation uses case class and the ordinary alternative combinator.

We implemented two more versions. One is a modified version of our implementation,
with object algebra replaced by case class for the ASTs.
The other is a modified version of Ilya's implementation, using the longest match
alternative combinator instead of the ordinary one.

\huang{done}\bruno{A table showing a summary of results is missing here. We discussed this before.}

\begin{table}
    \centering
    \begin{tabular}{|l|r|r|r|r|r|r|r|}
      \hline
        \multirow{2}{*}{\bfseries Calculus Name} & \bfseries Ilya's & \multicolumn{2}{ c| }{\bfseries Ours} & \multicolumn{2}{ c| }{\bfseries Ilya's with \inlinecode{|||}} & \multicolumn{2}{ c| }{\bfseries Ours with class} \\ \cline{3-8}
        \multicolumn{1}{|c|}{} & \multicolumn{1}{c|}{\bfseries Time} & \bfseries Time & \bfseries (+/-)\% & \bfseries Time & \bfseries (+/-)\% & \bfseries Time & \bfseries (+/-)\% \\
      \hline
        Arith & 741 & 913 & +23.2 & 793 & +7.0 & 932 & +25.8 \\
        Untyped & 770 & 1018 & +32.2 & 821 & +6.6 & 1007 & +30.8 \\
      \hline
        \multicolumn{1}{|c|}{\dots} & \multicolumn{7}{c|}{\dots} \\
      \hline
        FullRecon & 1094 & 1645 & +50.4 & 1161 & +6.1 & 1652 & +51.0 \\
        FullPoly & 1398 & 2086 & +49.2 & 1511 & +8.1 & 2019 & +44.4 \\
        FullOmega & 1451 & 2352 & +62.1 & 1582 & +9.0 & 2308 & +59.1 \\
      \hline
        Total & 21746 & 31024 & +42.7 & 23260 & +7.0 & 30795 & +41.6 \\
      \hline
    \end{tabular}
    \caption{Execution time of four versions}
    \label{tab:ext-comparison}
\end{table}

Table \ref{tab:ext-comparison} shows part of the comparison results of these four versions,
full table is available online []. It suggests that the difference of running time between
using object algebra and class is little, roughly 1\%.
The usage of longest match combinator slows the performance by 7\%. The main reason of slower
execution time may be the overall structure of the modular parsing approach, because we indeed have
more intermediate function calls and method overriding. However, it is worth metioning that
because of the memoization technique of Packrat parsers, we are only constant times
slower, the algorithmic complexity is still the same.
