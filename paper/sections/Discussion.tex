\section{More Features}

The use of inheritance-based approach and Object Algebras enables us to build modular parsers, which are able to evolve with syntax together. This section explores more interesting features, including overriding existing parsing rules, language components for abstracting language features, and alternative techniques under the whole framework.

\subsection{Overriding Existing Rules}

Just as many parser generators do\huang{???}, our pattern also supports overriding part of existing parsers, but in a type-safe way.
We can easily update existing parsing rules with new implementations, or eliminate them in extended parsers. As an illustration, suppose we have an untyped lambda abstraction case in a base parser as below. \inlinecode{pLam} parses a lambda symbol, an identifier, a dot and an expression in sequence. Some irrelevant details are omitted.

\lstinputlisting[linerange=7-12]{../Scala/Parser/src/PaperCode/Sec5/Code1.scala}% APPLY:linerange=BASEPARSER_UNTYPEDLAM

Then we want to replace the untyped lambda abstractions by typed lambdas. With inheritance and method overriding, it is easy to only change the implementation of \lstinline{pLam} in the extended parser. The new \inlinecode{pLam} parses a colon and a type in addition, between the identifier and the dot. Due to dynamic dispatch, our new explanation of lambdas will make a difference without affecting the other parts of the parser.

\lstinputlisting[linerange=16-22]{../Scala/Parser/src/PaperCode/Sec5/Code1.scala}% APPLY:linerange=EXTPARSER_TYPEDLAM


One can even ``eliminate'' a production rule in the extension, by actually overriding it with a failure parser. The lexer can also be updated, since keywords and delimiters are represented by sets of strings.

It is natural to keep overriding existing parsers, whereas another potential use of this pattern is to reuse old versions of a parser. For instance,
we have a \lstinline{NewParser} that extends \lstinline{ExtParser}, with some more cases added, but for the lambda case we want to go back to the untyped one.
It can be done by copying the code from \lstinline{BaseParser} again, yet does not achieve code reuse. Instead, we can instantiate an instance of \lstinline{BaseParser} to obtain the old \lstinline{pLam}:
\haoyuan{I don't know if this works or makes sense.}

\lstinputlisting[linerange=26-32]{../Scala/Parser/src/PaperCode/Sec5/Code1.scala}% APPLY:linerange=NEWPARSER_UNTYPEDLAM

\subsection{Language Component}

Having pointed out that our goal is to realize modular parsers, we expect the code written in an extensible way. We have been focusing on how to extend a language with some additional cases, just as many extensible compilers do, nevertheless, in other cases, languages are defined separately, and the composition of them is again a matter of code reuse. In this section, we propose a framework for defining small languages as modular components, in order for better composition.

The framework we use for a language, or rather a language component in our case study, consists of three parts: syntax, parsing and operations on the AST. More
specifically:
\begin{itemize}
    \item \textbf{Object Algebra interface:} defined as a trait for the abstract syntax. The type parameters represent multiple sorts of syntax, and the methods are constructs.
\item \textbf{Parser:} implementation of the parser with lexing, using inheritance and Object Algebras, with its scoping trait abstracted over the type parameters.
\item \textbf{Algebras (optional):} concrete operations on ASTs, such as pretty-printing.
\end{itemize}

Taking again the example in Section~\ref{subsec:parsingwithoa}. The language constructs consists of literals, additions and variables. First we define the
language component in a Scala object, shown in the left part of Figure~\ref{fig:lng-components}.

\begin{figure}[t]
\begin{tabular}{m{0.42\linewidth}m{0.52\linewidth}}
\lstinputlisting[linerange=44-59]{../Scala/Parser/src/PaperCode/Sec5/Code1.scala}% APPLY:linerange=LANGUAGE_COMPONENTS_VAREXPR
&
\lstinputlisting[linerange=63-78]{../Scala/Parser/src/PaperCode/Sec5/Code1.scala}% APPLY:linerange=LANGUAGE_COMPONENTS_TYPEDLAM
\end{tabular}
\caption{Language \lstinline{VarExpr} (left) and language \lstinline{TypedLam} (right).}\label{fig:lng-components}
\end{figure}

For the example in Section~\ref{subsec:differentsyntax}, instead of building inheritance directly, we define the language separately,
which consists of types and typed lambda expressions. Shape of the code is presented in the right of Figure~\ref{fig:lng-components}.

At this point, one may want those two language components to be composed into one, and meanwhile ensure that the one is still a modular
component ready for future composition. In that case modularity is realized over higher-order hierarchies. The composed language \lstinline{VarLamExpr}
is shown below:

\lstinputlisting[linerange=82-91]{../Scala/Parser/src/PaperCode/Sec5/Code1.scala}% APPLY:linerange=LANGUAGE_COMPONENTS_VARLAMEXPR
Note that lexing code is automatically combined under multiple inheritance. The combined language shows perfect modularity. The only
drawback is that the glue code of composition appears to be boilerplate. As shown above, we are combining ASTs, parsers and pretty printers of
\lstinline{VarExpr} and \lstinline{TypedLam} respectively. Such a pattern refers to \textit{family polymorphism}[]. Unfortunately Scala does not
support this feature, nonetheless, one can avoid such boilerplate by using metaprogramming techniques.

\subsection{Alternative Techniques}
Under our modular parsing framework, we use Packrat parsing as the underlying parsing technique, OO inheritance with method overriding for composing and extending parsers, and Object Algebras for parsing extensible ASTs. However, our framework is more general and thus more powerful, because those aspects are orthogonal to each other, and hence can have their alternatives.

\begin{itemize}

\item {\bf Parsing Technique}

Our approach does not depend on a particular parser combinator library or parsing algorithm. We demonstrated that Packrat parsing has some advantages and is suitable in a modular setting. However, under certain circumstances or in other programming languages, it may not be the best choice. One can use other parser combinator libraries as long as it meets his requirements.

\item {\bf Composing and Extending Parsers}

We use traits to model parsers, OO inheritance to compose them, and method overriding for their extensibility. These language features may not be supported in other programming languages, especially in functional languages such as Haskell. Nevertheless, \textit{open recursion} could be used as an alternative. An explict ``self-reference'' parameter is able to explain the recursive calls dynamically, by the real argument passed at runtime.

\item {\bf Extensible ASTs}

Besides Object Algebras, many other techniques including \textit{Data types Ã  la carte} (DTC) [] and \textit{Modular reifiable matching} (MRM) [] also support extensible data structures. These alternatives can also be adopted to build ASTs and corresponding parsers.

\end{itemize}

As we demonstrated, the whole modular parsing framework itself is modular, which means it can be customized easily. Actually, we conducted some previous experiments of modular paring in Haskell, based on open recursion, MRM and Parsec. However, we suffered from issues of Parsec, as illustrated in Section~\ref{subsec:challenges}. 
